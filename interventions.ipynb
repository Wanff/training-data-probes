{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional, Tuple, Dict, Union\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import openai\n",
    "import datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from utils import untuple\n",
    "from get_activations import gen_pile_data, compare_token_lists, slice_acts\n",
    "\n",
    "from act_add.model_wrapper import ModelWrapper\n",
    "from act_add.rep_reader import RepReader, CAARepReader, PCARepReader\n",
    "from act_add.contrast_dataset import ContrastDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:20<00:00,  6.78s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"EleutherAI/pythia-12b\"\n",
    "file_path = 'data/12b'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "all_mem_12b_data = pd.read_csv(f'{file_path}/mem_evals_gen_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteeringPipeline():\n",
    "    def __init__(self, model_wrapper : ModelWrapper, contrast_dataset : ContrastDataset, rep_reader : RepReader):\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.contrast_dataset = contrast_dataset\n",
    "        self.rep_reader = rep_reader\n",
    "                            \n",
    "        self.model_wrapper.wrap_all()\n",
    "    def gen_dir_from_states(self, \n",
    "                            pos_hidden_states,\n",
    "                            neg_hidden_states,\n",
    "                            hidden_layers : Union[List[int], int] = -1,\n",
    "                            n_difference : int = 1,\n",
    "                            train_labels: List[int] = None,):\n",
    "        \n",
    "        if not isinstance(hidden_layers, list): \n",
    "            assert isinstance(hidden_layers, int)\n",
    "            hidden_layers = [hidden_layers]\n",
    "        \n",
    "        assert pos_hidden_states.shape[0] == neg_hidden_states.shape[0], \"pos and neg hidden states must have same number of examples\"\n",
    "        \n",
    "        #*this is if shape is n_examples x n_layers x n_hidden\n",
    "        # interweaved = [torch.stack([pos_hidden_states[i], neg_hidden_states[i]], dim = 0) for i in range(pos_hidden_states.shape[0])]\n",
    "        # hidden_states = torch.cat(interweaved, dim=0)\n",
    "        \n",
    "        #*this is if shape is n_layers x n_examples x n_hidden\n",
    "        interweaved = [torch.stack([pos_hidden_states[:, i], neg_hidden_states[:, i]], dim = 1) for i in range(pos_hidden_states.shape[1])]\n",
    "        hidden_states = torch.cat(interweaved, dim=1)\n",
    "        \n",
    "        relative_hidden_states = self._gen_rel_states(hidden_states, hidden_layers, n_difference)\n",
    "        \n",
    "        return self._gen_dir(hidden_states, \n",
    "                             relative_hidden_states, \n",
    "                             hidden_layers, \n",
    "                             train_labels)\n",
    "        \n",
    "    def _gen_dir(self,       \n",
    "                hidden_states,   \n",
    "                relative_hidden_states,               \n",
    "                hidden_layers : Union[List[int], int] = -1,\n",
    "                train_labels: List[int] = None,\n",
    "                        ):\n",
    "        \n",
    "        # get the directions\n",
    "        directions = self.rep_reader.get_rep_directions(\n",
    "            self.model_wrapper.model, self.model_wrapper.tokenizer, relative_hidden_states, hidden_layers,\n",
    "            train_choices=train_labels)\n",
    "\n",
    "        for layer in self.rep_reader.directions:\n",
    "            if type(self.rep_reader.directions[layer]) == np.ndarray:\n",
    "                self.rep_reader.directions[layer] = self.rep_reader.directions[layer].astype(np.float32)\n",
    "\n",
    "        self.rep_reader.direction_signs = self.rep_reader.get_signs(\n",
    "            hidden_states, train_labels, hidden_layers)\n",
    "        \n",
    "        return self.rep_reader.directions\n",
    "        \n",
    "    def _gen_rel_states(self, hidden_states, hidden_layers, n_difference):\n",
    "        #*hidden_states should be a tensor or tuple of tensors of shape (n_layers, n_examples, n_hidden)\n",
    "        \n",
    "        if isinstance(hidden_states, dict):\n",
    "            relative_hidden_states = {k: np.copy(v) for k, v in hidden_states.items()}\n",
    "            \n",
    "        else:\n",
    "            relative_hidden_states = {k: np.copy(hidden_states[k]) for k in range(hidden_states.shape[0])}\n",
    "        \n",
    "        if isinstance(self.rep_reader, PCARepReader):\n",
    "            # get differences between pairs\n",
    "            for layer in hidden_layers:\n",
    "                for _ in range(n_difference):\n",
    "                    relative_hidden_states[layer] = relative_hidden_states[layer][::2] - relative_hidden_states[layer][1::2]\n",
    "        elif isinstance(self.rep_reader, CAARepReader):\n",
    "            #* IMPORTANT: All RepReaders expects that the order of the training data is alternating like: [p, n, p, n, ...]\n",
    "                for layer in hidden_layers:\n",
    "                    relative_hidden_states[layer] = relative_hidden_states[layer][::2] - relative_hidden_states[layer][1::2]\n",
    "        \n",
    "        return relative_hidden_states\n",
    "                        \n",
    "    def gen_dir_from_strings(self, \n",
    "                        train_inputs: Union[str, List[str], List[List[str]]], \n",
    "                        rep_token_idx : int = -1, \n",
    "                        hidden_layers : Union[List[int], int] = -1,\n",
    "                        n_difference : int = 1,\n",
    "                        train_labels: List[int] = None,):\n",
    "        self.model_wrapper.reset()\n",
    "        \n",
    "        if not isinstance(hidden_layers, list): \n",
    "            assert isinstance(hidden_layers, int)\n",
    "            hidden_layers = [hidden_layers]\n",
    "\n",
    "        # get raw hidden states for the train inputs\n",
    "        hidden_states = self.model_wrapper.batch_hiddens(train_inputs, \n",
    "                                                        hidden_layers, \n",
    "                                                        rep_token_idx, \n",
    "                                                        )['resid']\n",
    "        relative_hidden_states = self._gen_rel_states(hidden_states, hidden_layers, n_difference)\n",
    "        \n",
    "        return self._gen_dir(hidden_states, \n",
    "                             relative_hidden_states, \n",
    "                             hidden_layers, \n",
    "                             train_labels)\n",
    "\n",
    "        \n",
    "    def batch_steering_generate(self, \n",
    "                                inputs : List[str], \n",
    "                                layers_to_intervene : List[int],\n",
    "                                coeff : float = 1.0,\n",
    "                                token_pos : Union[str, int] = None,\n",
    "                                batch_size=8, \n",
    "                                operator = \"linear_comb\",\n",
    "                                use_tqdm=True,\n",
    "                                **generation_kwargs,\n",
    "                                ):\n",
    "        \n",
    "        assert self.rep_reader.directions is not None, \"Must generate rep_reader directions first\"\n",
    "        \n",
    "        #? do i need to do half() here?\n",
    "        steering_vectors = {}\n",
    "        for layer in layers_to_intervene:\n",
    "            if isinstance(self.rep_reader.directions[layer], np.ndarray):\n",
    "                steering_vectors[layer] = torch.tensor(coeff * self.rep_reader.directions[layer] * self.rep_reader.direction_signs[layer]).to(self.model_wrapper.model.device).half()\n",
    "            else:\n",
    "                steering_vectors[layer] = (coeff * self.rep_reader.directions[layer] * self.rep_reader.direction_signs[layer]).to(self.model_wrapper.model.device).half()\n",
    "\n",
    "        self.model_wrapper.reset()\n",
    "        self.model_wrapper.set_controller(layers_to_intervene, steering_vectors, masks=1, token_pos = token_pos, operator = operator)\n",
    "        generated = []\n",
    "\n",
    "        iterator = tqdm(range(0, len(inputs), batch_size)) if use_tqdm else range(0, len(inputs), batch_size)\n",
    "\n",
    "        for i in iterator:\n",
    "            inputs_b = inputs[i:i+batch_size]\n",
    "            decoded_outputs = self.model_wrapper.batch_generate_from_string(inputs_b, **generation_kwargs)\n",
    "            decoded_outputs = [o.replace(i, \"\") for o,i in zip(decoded_outputs, inputs_b)]\n",
    "            generated.extend(decoded_outputs)\n",
    "\n",
    "        self.model_wrapper.reset()\n",
    "        return generated\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_hiddens = torch.load(f'{file_path}/mem_all_hidden_states.pt')\n",
    "pile_hiddens = torch.load(f'{file_path}/pile_all_hidden_states.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4306, 7)\n",
      "(3373, 7)\n"
     ]
    }
   ],
   "source": [
    "mem_12b_data = all_mem_12b_data[all_mem_12b_data['char_by_char_similarity'] == 1]\n",
    "unmem_12b_data = all_mem_12b_data[all_mem_12b_data['char_by_char_similarity'] <= 0.55]\n",
    "\n",
    "print(mem_12b_data.shape)\n",
    "print(unmem_12b_data.shape)\n",
    "\n",
    "mem_pythia_idxs = mem_12b_data[mem_12b_data['source'] == 'pythia-evals']['idx_in_hidden_states'].values\n",
    "mem_pile_idxs = mem_12b_data[mem_12b_data['source'] == 'pile']['idx_in_hidden_states'].values\n",
    "unmem_pythia_idxs = unmem_12b_data[unmem_12b_data['source'] == 'pythia-evals']['idx_in_hidden_states'].values\n",
    "unmem_pile_idxs = unmem_12b_data[unmem_12b_data['source'] == 'pile']['idx_in_hidden_states'].values\n",
    "\n",
    "mem_hidden_states = torch.cat([mem_hiddens[mem_pythia_idxs], pile_hiddens[mem_pile_idxs]], dim = 0)\n",
    "unmem_hidden_states = torch.cat([mem_hiddens[unmem_pythia_idxs], pile_hiddens[unmem_pile_idxs]], dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3373\n",
    "\n",
    "def get_ground_truth_strings(data, low = 0.9, high =0.99):\n",
    "    ground_truth_strings = data[data['char_by_char_similarity'].between(low, high)]['ground'].tolist()\n",
    "    return ground_truth_strings\n",
    "\n",
    "def gen_eval_data(ground_strings, tokenizer, input_length = 32, max_length = 64):\n",
    "    tokens = tokenizer(ground_strings, padding = True, truncation = True, max_length = max_length, return_tensors = 'pt')\n",
    "    inputs = tokenizer.batch_decode(tokens['input_ids'][:, :input_length])\n",
    "    targets = tokenizer.batch_decode(tokens['input_ids'][:, input_length:])\n",
    "    return inputs, targets\n",
    "\n",
    "memmed_ground_truth_strings = get_ground_truth_strings(all_mem_12b_data, low = 1, high = 1)\n",
    "\n",
    "unseen_memmed_ground = memmed_ground_truth_strings[N:N + 10]\n",
    "inputs, targets = gen_eval_data(unseen_memmed_ground, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import Levenshtein\n",
    "\n",
    "sim_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "def sim_scores(outputs, targets):\n",
    "    semantic_scores_gen = []\n",
    "    for target, output in zip(targets, outputs):\n",
    "        embedding1 = sim_model.encode(target, convert_to_tensor=True)\n",
    "        embedding2 = sim_model.encode(output, convert_to_tensor=True)\n",
    "        cosine_sim_gen = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "        similarity_value_gen = cosine_sim_gen.item()\n",
    "        semantic_scores_gen.append(similarity_value_gen)\n",
    "    \n",
    "    return semantic_scores_gen \n",
    "\n",
    "def char_by_char_similarity(outputs, targets):\n",
    "    similarities = []\n",
    "    for o, t in zip(outputs, targets):\n",
    "        o = re.sub(r'\\s', '', o)\n",
    "        t = re.sub(r'\\s', '', t)\n",
    "\n",
    "        o = o.lower()\n",
    "        t = t.lower()\n",
    "\n",
    "        # remove '<|endoftext|>'\n",
    "        o = o.replace('<|endoftext|>', '')\n",
    "        t = t.replace('<|endoftext|>', '')\n",
    "\n",
    "        max_len = max(len(o), len(t))\n",
    "        matches = [c1 == c2 for c1, c2 in zip(o, t)]\n",
    "        \n",
    "        similarities.append(sum(matches)/max_len if max_len > 0 else 0)\n",
    "    return similarities\n",
    "\n",
    "def compare_token_lists(ground_toks, genned_toks):\n",
    "    if len(ground_toks) != len(genned_toks):\n",
    "        # print(len(ground_toks), len(genned_toks))\n",
    "        # print(\"Both lists do not have the same length.\")\n",
    "        return 0\n",
    "    \n",
    "    num_same_tokens = sum(1 for token1, token2 in zip(ground_toks, genned_toks) if token1 == token2)\n",
    "    percent_same_tokens = (num_same_tokens / len(ground_toks)) \n",
    "    \n",
    "    return percent_same_tokens\n",
    "\n",
    "def tok_by_tok_similarity(outputs, targets):\n",
    "    o_tokens = tokenizer(outputs, return_tensors = 'pt',padding = False, truncation = True, max_length = 64)['input_ids']\n",
    "    t_tokens = tokenizer(targets, return_tensors = 'pt',padding = False, truncation = True, max_length = 64)['input_ids']\n",
    "    print(o_tokens)\n",
    "    print(t_tokens)\n",
    "    return [compare_token_lists(t, o) for t, o in zip(t_tokens, o_tokens)]\n",
    "\n",
    "def levenshtein_distance(outputs, targets):\n",
    "    diss = []\n",
    "    for o, t in zip(outputs, targets):\n",
    "        max_len = max(len(o), len(t))\n",
    "        diss.append((max_len - Levenshtein.distance(o, t)) / max_len)\n",
    "    return diss\n",
    "\n",
    "def extract_quote_completion(s):\n",
    "    s = s.replace(\";\",\",\").split(\".\")[0].split(\"\\n\")[0]\n",
    "    return s.strip().lower()\n",
    "\n",
    "def eval_completions(outputs, targets, return_mean = True):\n",
    "    cbc_sims = char_by_char_similarity(outputs, targets)\n",
    "    # tbt_sims = tok_by_tok_similarity(outputs, targets)\n",
    "    sem_sims = sim_scores(outputs, targets)\n",
    "    lev_diss = levenshtein_distance(outputs, targets)\n",
    "    \n",
    "    # outputs = [extract_quote_completion(o) for o in outputs]\n",
    "    # em = np.mean([t in o for t,o in zip(targets,outputs)])\n",
    "    \n",
    "    if return_mean:\n",
    "        return {'char_by_char_similarity': np.mean(cbc_sims),\n",
    "                # 'tok_by_tok_similarity': np.mean(tbt_sims),\n",
    "                'sem_similarity': np.mean(sem_sims),\n",
    "                'lev_distance': np.mean(lev_diss),\n",
    "                # 'em': np.mean(em),\n",
    "                }\n",
    "    else:\n",
    "        return {'char_by_char_similarity': cbc_sims,\n",
    "                # 'tok_by_tok_similarity': tbt_sims,\n",
    "                'sem_similarity': sem_sims,\n",
    "                'lev_distance': lev_diss,\n",
    "                # 'em': em,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pure mem - random unmem pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "N = unmem_hidden_states.shape[0]\n",
    "mem_contra_dataset = ContrastDataset(mem_12b_data['gen'].tolist()[:N], \n",
    "                               unmem_12b_data['gen'].tolist()[:N], \n",
    "                               model_name_or_path,\n",
    "                               use_convo_format=False,\n",
    "                               system_prompt=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_rep_reader = CAARepReader()\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, mem_contra_dataset, mem_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_IDX = 9\n",
    "N_LAYERS = model.config.num_hidden_layers\n",
    "rep_token_idx = -1\n",
    "hidden_layers = list(range(model.config.num_hidden_layers))\n",
    "n_difference = None\n",
    "train_labels = None\n",
    "\n",
    "mem_rr_hidden_states = mem_hidden_states[:N, :, TOKEN_IDX, :].reshape(N_LAYERS, N, -1)\n",
    "unmem_rr_hidden_states = unmem_hidden_states[:N, :, TOKEN_IDX, :].reshape(N_LAYERS, N, -1)\n",
    "\n",
    "dirs = mem_steering_pipeline.gen_dir_from_states(mem_rr_hidden_states, unmem_rr_hidden_states, hidden_layers, n_difference, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 1\n",
      "LAYERS: [30, 35]\n",
      "RepReader:\n",
      "No Control\n",
      "{'char_by_char_similarity': 0.9044715447154472, 'sem_similarity': 0.9756519377231598}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.7586262106140647, 'sem_similarity': 0.9292394697666169}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.5532528697283654, 'sem_similarity': 0.7501227796077728}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "layer_id = [30, 35]\n",
    "\n",
    "batch_size=50\n",
    "coeff=1 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "# baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "#                                                                 layer_id, \n",
    "#                                                                 coeff = 0 * coeff, \n",
    "#                                                                 batch_size = batch_size, \n",
    "#                                                                 use_tqdm=True, \n",
    "#                                                                 max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\tmargin-top: -22px;\\n\\tmargin-',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ' is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an “AS IS” BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_RD_CTL_D2                                0x28bc\\n',\n",
       " '                \\n                }\\n            },\\n            \"axisTick\": {\\n                \"show\": true,\\n                \"lineStyle\": {\\n                    \" color',\n",
       " '\\n background-image: url(fancybox_loading.gif);\\n background-repeat: no-repeat center center;\\n background-position: center',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n public static final String ER_PROCESS_ is not a known element. The document is the root document of the document. in the document.',\n",
       " ',\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing the defense of res judicata, the right to the, and the right to the, and the right to the, and the',\n",
       " '</a> <a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class',\n",
       " 'void) collectionView:(UICollectionView *)collectionView didSelectItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    [self.collection']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL                                   0x28bc\\n#define',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tbackground-image: url(fancybox_loading.png);\\n}\\n\\n#fancybox-error {\\n\\tbackground-image',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n\\n  public static final String ER_NO_OUTPUT_SPECIFIER = \"ER_NO_OUTPUT_SPECIFIER\";\\n  public',\n",
       " '\\tSec  int64\\n\\tUsec int64\\n}\\n\\nfunc NewPopulatedMessage(r int64) *Message_Container.MessageBuilder {',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a></div>\\n            </div>\\n        </div>\\n        <div id=\"dac-content\" id=\"content\">\\n        ',\n",
       " 'UITableViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    static NSString']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probe direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes import LRProbe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datasets import load_from_disk\n",
    "# Combine memmed and non_memmed hidden states\n",
    "path = 'data/12b'\n",
    "dataset = load_from_disk(os.path.join(path, 'split_hf_token_dataset_vary_len_v2'))\n",
    "LAYER = 34\n",
    "TOK_IDXS = [5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4047, 7) (675, 7) (2024, 7)\n"
     ]
    }
   ],
   "source": [
    "train_rows = all_mem_12b_data.loc[dataset['train']['df_ref_idx'][:int(len(dataset['train']['df_ref_idx']) / 5)]]\n",
    "val_rows = all_mem_12b_data.loc[dataset['val']['df_ref_idx'][:int(len(dataset['val']['df_ref_idx']) / 5)]]\n",
    "test_rows = all_mem_12b_data.loc[dataset['test']['df_ref_idx'][:int(len(dataset['test']['df_ref_idx']) / 5)]]\n",
    "\n",
    "print(train_rows.shape, val_rows.shape, test_rows.shape)\n",
    "\n",
    "def rows_to_X_y(rows, layer = None, tok_idxs = None):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, row in rows.iterrows():\n",
    "        if row['source'] == 'pythia-evals':\n",
    "            X.append(mem_hiddens[row['idx_in_hidden_states']])\n",
    "        elif row['source'] == 'pile':\n",
    "            X.append(pile_hiddens[row['idx_in_hidden_states']])\n",
    "        \n",
    "        if row['char_by_char_similarity'] == 1:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "        \n",
    "    if tok_idxs is not None and layer is not None:\n",
    "        y = torch.from_numpy(np.array([[label] * len(tok_idxs) for label in y]).flatten())\n",
    "        \n",
    "        new_X = []\n",
    "        for x in X:\n",
    "            new_X.append(torch.stack([x[layer, tok_idx] for tok_idx in tok_idxs]))\n",
    "        return torch.cat(new_X, dim = 0).float(), y.float()\n",
    "    else:\n",
    "        return torch.stack(X, dim = 0).float(), torch.tensor(y).float()\n",
    "X_train, y_train = rows_to_X_y(train_rows, layer = LAYER, tok_idxs = TOK_IDXS)\n",
    "X_val, y_val = rows_to_X_y(val_rows, layer = LAYER, tok_idxs = TOK_IDXS)\n",
    "X_test, y_test = rows_to_X_y(test_rows, layer = LAYER, tok_idxs = TOK_IDXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBE LAYER 34 TOKEN [5, 6, 7, 8, 9]\n",
      "Accuracy 0.9277036786079407\n",
      "AUC 0.9780742015345987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.05\n",
    "weight_decay = 1\n",
    "epochs = 500\n",
    "use_bias = True\n",
    "normalize = False\n",
    "\n",
    "if normalize:\n",
    "    X_train = (X_train - X_train.mean(dim = 0)) / X_train.std(dim = 0)\n",
    "    X_val = (X_val - X_train.mean(dim = 0)) / X_train.std(dim = 0)\n",
    "\n",
    "probe = LRProbe.from_data(X_train, y_train, \n",
    "                          lr = lr, \n",
    "                          weight_decay = weight_decay, \n",
    "                          epochs = epochs, \n",
    "                          use_bias = use_bias,\n",
    "                          device = \"cuda\", )\n",
    "\n",
    "acc = probe.get_probe_accuracy(X_val, y_val, device = \"cuda\")\n",
    "auc = probe.get_probe_auc(X_val, y_val, device = \"cuda\")\n",
    "\n",
    "print(f\"PROBE LAYER {LAYER} TOKEN {TOK_IDXS}\")\n",
    "print(f\"Accuracy {acc}\")\n",
    "print(f\"AUC {auc}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9534814814814815, 0.9854827664916684)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Create an instance of Logistic Regression\n",
    "probe_lr = LogisticRegression(max_iter = 5000, C = 1e-4)\n",
    "\n",
    "# Train the probe using the training data\n",
    "probe_lr.fit(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "# Predict the labels for X_val\n",
    "y_pred = probe_lr.predict(X_val.numpy())\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val.numpy(), y_pred)\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(y_val.numpy(), probe_lr.predict_proba(X_val.numpy())[:, 1])\n",
    "\n",
    "accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0008365 ,  0.00400184, -0.00156602, ...,  0.00412694,\n",
       "         0.00427111, -0.00088022]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34: 1}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from act_add.rep_reader import ProbeRepReader\n",
    "\n",
    "# probe_rep_reader = ProbeRepReader({\n",
    "#     34: probe\n",
    "# })\n",
    "probe_rep_reader = ProbeRepReader({\n",
    "    34: torch.from_numpy(probe_lr.coef_[0]) / torch.norm(torch.from_numpy(probe_lr.coef_[0]), p = 2)\n",
    "})\n",
    "probe_rep_reader.get_rep_directions([34])\n",
    "probe_rep_reader.get_signs([34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = probe_rep_reader.directions[34]\n",
    "current = mem_hiddens[:10, 4:10, 9]\n",
    "\n",
    "projection = torch.sum(current.float() * controller.float().reshape(1, 1, -1), dim = 2).unsqueeze(2) * controller.float().reshape(1, 1, -1)\n",
    "if current.dtype == torch.float16:\n",
    "    projection = projection.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, None, probe_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 1\n",
      "LAYERS: [34]\n",
      "RepReader:\n",
      "No Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.8393921796360821, 'sem_similarity': 0.9588506340980529, 'lev_distance': 0.921724622409554}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.8393921796360821, 'sem_similarity': 0.9588506340980529, 'lev_distance': 0.921724622409554}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.8393921796360821, 'sem_similarity': 0.9588506340980529, 'lev_distance': 0.921724622409554}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "layer_id = [34]\n",
    "\n",
    "batch_size=50\n",
    "coeff=1 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                                layer_id, \n",
    "                                                                coeff = 0 * coeff, \n",
    "                                                                batch_size = batch_size, \n",
    "                                                                use_tqdm=True, \n",
    "                                                                operator = \"projection\",\n",
    "                                                                max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            operator = \"projection\",                                    \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            operator = \"projection\",\n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\tmargin-top: -22px;\\n\\tmargin-',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ' is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\tmargin-top: -22px;\\n\\tmargin-',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  Unless required by applicable law or agreed to in writing, software\\n *  distributed under BSD teasp\"), etc.)\\n *\\n *  You should have received',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_RD_CTL_D2                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": $[]$[],\\n            \"axisTickLabel\": {\\n                \"empty\": true\\n            },\\n',\n",
       " '\\n\\tbackground-image: url(fancybox_loading.png);\\n}\\n\\n#fancybox-error {\\n\\tbackground-image',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\"; \\n  /** \\n   *  user0 \\n   */ \\n  public static final String ER_INVALID_OUTPUT_TYPE = \\n         \"ER',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc teaspb(data teaspbData) teaspbResultTable {\\n\\tresult',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions                      notices \\n\\xa0\\n \\xa0\\n \\xa0\\n \\xa0\\n \\xa0\\n \\xa0\\n                                                                          NOTICE\\xa0\\n                                                                          \\xa0\\n \\xa0\\n                                                                           \\xa0\\n \\xa0\\n \\xa0\\n \\xa0\\n',\n",
       " '</a><a href=\"#gadcfb0e0e0e0e0e0e0e0e0e0e0e',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView \\n         cellForItemAtIndexPath:(NSIndexPath *)indexPath \\n         ']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR--REG-- P-REG-- P-REG--',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color: #',\n",
       " '\\n\\t position: fixed; right: 50%; top: 50%; z-index: 100; -moz-border-radius: 6px 6px 6',\n",
       " ' 2027........... 677.68\\nApril 2027........... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT: \" +\\n\"An attempt was made to PUSH a PUSH- type PUSH-- PUSH- type... and the PUSH was',\n",
       " '\\n “\\n\\n… “\\n\\n… “\\n\\n… “\\n\\n… “\\n\\n… “\\n\\n… “\\n\\n… “\\n\\n',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pure mem - reshuffled mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# N = unmem_hidden_states.shape[0]\n",
    "N = 100\n",
    "\n",
    "shuffled_memmed_prompts = []\n",
    "for prompt in mem_12b_data['gen'].tolist():\n",
    "    tokens = tokenizer.tokenize(prompt)\n",
    "    random.shuffle(tokens)\n",
    "    detokenized_prompt = tokenizer.convert_tokens_to_string(tokens)\n",
    "    shuffled_memmed_prompts.append(detokenized_prompt)\n",
    "\n",
    "mem_contra_dataset = ContrastDataset(mem_12b_data['gen'].tolist()[:N], \n",
    "                               shuffled_memmed_prompts[:N], \n",
    "                               model_name_or_path,\n",
    "                               use_convo_format=False,\n",
    "                               system_prompt=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_rep_reader = CAARepReader()\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, mem_contra_dataset, mem_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 100, 5120])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_IDX = 9\n",
    "N_LAYERS = model.config.num_hidden_layers\n",
    "rep_token_idx = -1\n",
    "hidden_layers = list(range(model.config.num_hidden_layers))\n",
    "n_difference = None\n",
    "train_labels = None\n",
    "\n",
    "mem_rr_hidden_states = mem_hidden_states[:N, :, TOKEN_IDX, :].reshape(N_LAYERS, N, -1)\n",
    "mem_rr_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff_mem_rr_hidden_states = mw.batch_to_hiddens(shuffled_memmed_prompts[:N],\n",
    "                                                          layers = hidden_layers,\n",
    "                                                          token_idx=rep_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff_mem_rr_hidden_states = torch.stack([shuff_mem_rr_hidden_states[i] for i in shuff_mem_rr_hidden_states.keys()], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = mem_steering_pipeline.gen_dir_from_states(mem_rr_hidden_states, shuff_mem_rr_hidden_states, hidden_layers, n_difference, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 0.2\n",
      "LAYERS: [30]\n",
      "RepReader:\n",
      "No Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.7090909090909092, 'sem_similarity': 0.9499296605587005}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.46361896812594566, 'sem_similarity': 0.8107414603233337}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.6406418256512403, 'sem_similarity': 0.9094023406505585}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "layer_id = [30]\n",
    "\n",
    "batch_size=50\n",
    "coeff=0.2 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                                layer_id, \n",
    "                                                                coeff = 0 * coeff, \n",
    "                                                                batch_size = batch_size, \n",
    "                                                                use_tqdm=True, \n",
    "                                                                max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intercom:before {\\n   content: \"\\\\f7af\"; }\\n \\n.fa-internet-explorer:before {\\n   content:',\n",
       " '\\n      <sourceFolder url=\"file://$MODULE_DIR$/src/debug/aidl\" isTestSource=\"false\" />\\n      <source',\n",
       " ' -16084379, -28926210, 15006023, 3284568, -6276540},\\n\\t\\t\\tFieldElement{23599295,',\n",
       " '��\\ue024\\ue025\\ue026\\ue027\\ue028\\ue029\\ue02a\\ue02b\\ue02c\\ue02d',\n",
       " ' twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nF',\n",
       " '.0.1\",\\n          \"resolved\": \"https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0',\n",
       " ' * with this source code for terms and conditions that govern your use of\\n * this software. Any use, reproduction, disclosure, or distribution of\\n * this',\n",
       " ' of a confidential source and, in the case of a record compiled by a criminal law enforcement authority in the course of a criminal investigation, or by an agency conducting',\n",
       " ' figures are approximations based upon third party submissions to SimplyHired or its affiliates. These figures are given to the SimplyHired users for the purpose of generalized comparison',\n",
       " 'exit_level_0:\\n        if( info == LAPACK_TRANSPOSE_MEMORY_ERROR ) {\\n            LAPACKE_']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instagram-square:before {\\n   content: \"\\\\f955\"; }\\n \\n.fa-intercom:before {\\n   content: \"\\\\f',\n",
       " '\\n      <sourceFolder url=\"file://$MODULE_DIR$/src/debug/aidl\" isTestSource=\"false\" />\\n      <source',\n",
       " ' -10864081, -818919, 1359789},\\n\\t\\t\\tFieldElement{14076899, -15673580, -',\n",
       " '\\ue023\\ue024\\ue025\\ue026\\ue027\\ue028\\ue029\\ue02a\\ue02b\\ue02c�',\n",
       " ' twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nF',\n",
       " '.0.1\",\\n          \"resolved\": \"https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0',\n",
       " ' * with this source code for terms and conditions that govern your use of\\n * this software. Any use, reproduction, disclosure, or distribution of\\n * this',\n",
       " ' the extent that the production of such records would...\\n(C) constitute an unwarranted invasion of personal privacy, (D) disclose the identity of a living person, and (E) disclose the location of a dead body.\\n\\nThe only exception to this rule is that the identity of a deceased',\n",
       " ' figures aresales and income and as such may differ from what you see reported on our website and when quoting for a job.\\n\\nPlease note that all',\n",
       " 'exit_level_0:\\n        if( info == ninfo ) {\\n            *info = iinfo;\\n        }\\n    }\\n    ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instagram-square:before {\\n   content: \"\\\\f081\"; }\\n \\n.fa-intercom:before {\\n   content: \"\\\\f',\n",
       " '\\n      <sourceFolder url=\"file://$MODULE_DIR$/src/debug/aidl\" isTestSource=\"false\" />\\n      <source',\n",
       " ' -16084379, -28926210, 15006023, -3633890, -18942047, -10055357},\\n\\t\\t\\t',\n",
       " '\\ue023\\ue024\\ue025\\ue026\\ue027\\ue028\\ue029\\ue02a\\ue02b\\ue02c�',\n",
       " ' twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nF',\n",
       " '.0.1\",\\n          \"resolved\": \"https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0',\n",
       " ' * with this source code for terms and conditions that govern your use of this\\n * software.  Any use, reproduction, disclosure, or distribution of this software',\n",
       " ' the extent that the production of such records would...\\n(C) constitute an unwarranted invasion of personal privacy, (D) disclose the identity of a confidential source, (E) disclose the identity of an informant, or (F) disclose investigative techniques and procedures.\\n\\nThe court has determined that',\n",
       " ' figures are approximations based upon third party submissions to SimplyHired or its affiliates. These figures are given to the SimplyHired users for the purpose of generalized comparison',\n",
       " 'exit_level_0:\\n        if( info == LAPACK_TRANSPOSE_MEMORY_ERROR ) {\\n            LAPACKE_']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replicating repe quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.95s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\").eval()\n",
    "use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast = use_fast_tokenizer, padding_side=\"left\")\n",
    "tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n",
    "tokenizer.bos_token_id = 1\n",
    "\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../act-add-suite/data/memorization\"\n",
    "\n",
    "with open(os.path.join(data_dir, \"quotes/popular_quotes.json\")) as file:\n",
    "    seen_quotes = json.load(file)\n",
    "\n",
    "with open(os.path.join(data_dir, \"quotes/unseen_quotes.json\")) as file:\n",
    "    unseen_quotes = json.load(file)\n",
    "    \n",
    "format_fn = lambda s : \"{s} \".format(s=s) \n",
    "\n",
    "quotes_dataset = ContrastDataset(seen_quotes, unseen_quotes, model_name_or_path, \n",
    "                                 format_fn = format_fn,\n",
    "                                 use_chat=False, \n",
    "                                 system_prompt=\"\")\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = quotes_dataset.gen_train_test_split(48, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate completions for each quote\n",
    "real_quotes = train_data[::2]\n",
    "\n",
    "quotes_first_half = []\n",
    "completions = []\n",
    "for quote in real_quotes:\n",
    "    quote_parts = quote.split()\n",
    "    first_half = \" \".join(quote_parts[:len(quote_parts)//2])\n",
    "    second_half = \" \".join(quote_parts[len(quote_parts)//2:])\n",
    "    quotes_first_half.append(first_half)\n",
    "    \n",
    "completions = mw.batch_generate_from_string(quotes_first_half, max_new_tokens=10)\n",
    "\n",
    "# Evaluate completions\n",
    "evaluations = eval_completions(completions, real_quotes, return_mean = False)\n",
    "\n",
    "# Print the evaluations\n",
    "for i in range(len(real_quotes)):\n",
    "    print(f\"Quote: {real_quotes[i]}\")\n",
    "    print(f\"Completion: {completions[i]}\")\n",
    "    print(f\"char: {evaluations['char_by_char_similarity'][i]}\")\n",
    "    print(f\"lev: {evaluations['lev_distance'][i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: To be or not to be, that is the question. \n",
      "Completion: To be or not to be, that is the question.\" \"Whether '\n",
      "char: 0.7619047619047619\n",
      "lev: 0.7924528301886793\n",
      "\n",
      "Quote: In the end, we will remember not the words of our enemies, but the silence of our friends. \n",
      "Completion: In the end, we will remember not the words of our enemies, but the silence of our friends\n",
      "char: 0.9863013698630136\n",
      "lev: 0.978021978021978\n",
      "\n",
      "Quote: The only thing necessary for the triumph of evil is for good men to do nothing. \n",
      "Completion: The only thing necessary for the triumph of evil is for good men to do nothing.\" \"\n",
      "char: 0.9696969696969697\n",
      "lev: 0.975609756097561\n",
      "\n",
      "Quote: The unexamined life is not worth living. \n",
      "Completion: The unexamined life is not worth living.\n",
      "\n",
      "—Socrates\n",
      "char: 0.7906976744186046\n",
      "lev: 0.7843137254901961\n",
      "\n",
      "Quote: The future belongs to those who believe in the beauty of their dreams. \n",
      "Completion: The future belongs to those who believe in the beauty of their dreams.”\n",
      "\n",
      "\n",
      "char: 0.9830508474576272\n",
      "lev: 0.958904109589041\n",
      "\n",
      "Quote: Not everything that is faced can be changed, but nothing can be changed until it is faced. \n",
      "Completion: Not everything that is faced can be changed, but nothing can be changed until it is faced.\"\n",
      "char: 0.9866666666666667\n",
      "lev: 0.989010989010989\n",
      "\n",
      "Quote: It does not matter how slowly you go as long as you do not stop. \n",
      "Completion: It does not matter how slowly you go as long as you do not stop.\"\n",
      "\n",
      "char: 0.9803921568627451\n",
      "lev: 0.9696969696969697\n",
      "\n",
      "Quote: Injustice anywhere is a threat to justice everywhere. \n",
      "Completion: Injustice anywhere is a threat to justice everywhere.\n",
      "\n",
      "We are not\n",
      "char: 0.8518518518518519\n",
      "lev: 0.8307692307692308\n",
      "\n",
      "Quote: The journey of a thousand miles begins with one step. \n",
      "Completion: The journey of a thousand miles begins with a single step.\n",
      "\n",
      "—\n",
      "char: 0.7346938775510204\n",
      "lev: 0.8524590163934426\n",
      "\n",
      "Quote: Two things are infinite: the universe and human stupidity, and I'm not sure about the universe. \n",
      "Completion: Two things are infinite: the universe and human stupidity; and I'm not sure about the\n",
      "char: 0.875\n",
      "lev: 0.875\n",
      "\n",
      "Quote: If you judge people, you have no time to love them. \n",
      "Completion: If you judge people, you have no time to love them.\n",
      "\n",
      "—\n",
      "char: 0.9761904761904762\n",
      "lev: 0.9444444444444444\n",
      "\n",
      "Quote: The best way to predict the future is to create it. \n",
      "Completion: The best way to predict the future is to create it.\" \"The future\n",
      "char: 0.7884615384615384\n",
      "lev: 0.8125\n",
      "\n",
      "Quote: Life is what happens to us while we are making other plans. \n",
      "Completion: Life is what happens to us while we're busy making other plans.\" \"I\n",
      "char: 0.5454545454545454\n",
      "lev: 0.8507462686567164\n",
      "\n",
      "Quote: Whenever you find yourself on the side of the majority, it is time to pause and reflect. \n",
      "Completion: Whenever you find yourself on the side of the majority, it is time to pause and reflect\n",
      "char: 0.9861111111111112\n",
      "lev: 0.9775280898876404\n",
      "\n",
      "Quote: When one door of happiness closes, another opens. \n",
      "Completion: When one door of the house is closed, another door opens.\n",
      "\n",
      "char: 0.2765957446808511\n",
      "lev: 0.7241379310344828\n",
      "\n",
      "Quote: Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring. \n",
      "Completion: Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.\"\n",
      "\n",
      "char: 0.9894736842105263\n",
      "lev: 0.9819819819819819\n",
      "\n",
      "Quote: The only true wisdom is in knowing you know nothing. \n",
      "Completion: The only true wisdom is in knowing you know nothing.\" \"I'm not\n",
      "char: 0.8431372549019608\n",
      "lev: 0.8548387096774194\n",
      "\n",
      "Quote: The truth will set you free, but first it will piss you off. \n",
      "Completion: The truth will set you free, but first it will piss you off.\" \"I\n",
      "char: 0.9411764705882353\n",
      "lev: 0.953125\n",
      "\n",
      "Quote: There is no passion to be found playing small - in settling for a life that is less than the one you are capable of living. \n",
      "Completion: There is no passion to be found playing small - in settling for a life that is less than the one you are\n",
      "char: 0.8367346938775511\n",
      "lev: 0.8387096774193549\n",
      "\n",
      "Quote: If you want to go fast, go alone. If you want to go far, go together. \n",
      "Completion: If you want to go fast, go alone. If you want to go far, go together.”\n",
      "char: 0.9818181818181818\n",
      "lev: 0.9857142857142858\n",
      "\n",
      "Quote: You must be the change you wish to see in the world. \n",
      "Completion: You must be the change you wish to see in the world.\" \"I am\n",
      "char: 0.8913043478260869\n",
      "lev: 0.8983050847457628\n",
      "\n",
      "Quote: Don't cry because it's over, smile because it happened. \n",
      "Completion: Don't cry because it's over, smile because it happened.\" \"I'm\n",
      "char: 0.9038461538461539\n",
      "lev: 0.9180327868852459\n",
      "\n",
      "Quote: The greatest glory in living lies not in never falling, but in rising every time we fall. \n",
      "Completion: The greatest glory in living lies not in never falling, but in rising every time we fall\n",
      "char: 0.9863013698630136\n",
      "lev: 0.9777777777777777\n",
      "\n",
      "Quote: Life is either a daring adventure or nothing at all. \n",
      "Completion: Life is either a daring adventure or nothing.\" \"I don't know which\n",
      "char: 0.6727272727272727\n",
      "lev: 0.7272727272727273\n",
      "\n",
      "Quote: Success is not final, failure is not fatal: It is the courage to continue that counts. \n",
      "Completion: Success is not final, failure is not fatal: it is the courage to continue that counts. Winston\n",
      "char: 0.9102564102564102\n",
      "lev: 0.9148936170212766\n",
      "\n",
      "Quote: If life were predictable it would cease to be life, and be without flavor. \n",
      "Completion: If life were predictable it would cease to be life.\n",
      "\n",
      "The only thing that\n",
      "char: 0.7213114754098361\n",
      "lev: 0.72\n",
      "\n",
      "Quote: Life is 10% what happens to us and 90% how we react to it. \n",
      "Completion: Life is 10% what happens to us and 90% how we react to it.\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9830508474576272\n",
      "\n",
      "Quote: The world is full of magical things patiently waiting for our wits to grow sharper. \n",
      "Completion: The world is full of magical things patiently waiting for our wits to grow sharper\n",
      "char: 0.9855072463768116\n",
      "lev: 0.9761904761904762\n",
      "\n",
      "Quote: It is better to be hated for what you are than to be loved for what you are not. \n",
      "Completion: It is better to be hated for what you are than loved for what you are not.\" \"\n",
      "char: 0.6129032258064516\n",
      "lev: 0.9012345679012346\n",
      "\n",
      "Quote: In this world nothing can be said to be certain, except death and taxes. \n",
      "Completion: In this world nothing can be said to be certain, except death and taxes.\" \"\n",
      "char: 0.9672131147540983\n",
      "lev: 0.9733333333333334\n",
      "\n",
      "Quote: The world breaks everyone, and afterward, some are strong at the broken places. \n",
      "Completion: The world breaks everyone, and afterward, some are strong at the broken places.\n",
      "\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9753086419753086\n",
      "\n",
      "Quote: Happiness is not something ready made. It comes from your own actions. \n",
      "Completion: Happiness is not something ready made. It comes from your own actions.\n",
      "\n",
      "-\n",
      "char: 0.9833333333333333\n",
      "lev: 0.958904109589041\n",
      "\n",
      "Quote: It's not what happens to you, but how you react to it that matters. \n",
      "Completion: It's not what happens to you, but how you react to it that matters.\" \"You\n",
      "char: 0.9152542372881356\n",
      "lev: 0.9315068493150684\n",
      "\n",
      "Quote: The only way to do great work is to love what you do. \n",
      "Completion: The only way to do great work is to love what you do. If you\n",
      "char: 0.8913043478260869\n",
      "lev: 0.9\n",
      "\n",
      "Quote: Life isn't about finding yourself. Life is about creating yourself. \n",
      "Completion: Life isn't about finding yourself. Life is about creating yourself.\"\n",
      "\n",
      "\"I\n",
      "char: 0.9508196721311475\n",
      "lev: 0.9305555555555556\n",
      "\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "counter =0 \n",
    "memmed_quotes_idxs = []\n",
    "for i in range(len(real_quotes)):\n",
    "    if evaluations['lev_distance'][i] > 0.7:\n",
    "        print(f\"Quote: {real_quotes[i]}\")\n",
    "        print(f\"Completion: {completions[i]}\")\n",
    "        print(f\"char: {evaluations['char_by_char_similarity'][i]}\")\n",
    "        print(f\"lev: {evaluations['lev_distance'][i]}\")\n",
    "        print()\n",
    "        counter +=1\n",
    "        memmed_quotes_idxs.append(i)\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_train_data = []\n",
    "good_train_labels = []\n",
    "for idx in memmed_quotes_idxs:\n",
    "    good_train_data.extend(train_data[idx*2:idx*2+2])\n",
    "    good_train_labels.extend(train_labels[idx*2:idx*2+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from act_add.rep_reader import PCARepReader\n",
    "quote_rep_reader = PCARepReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_steer_pipeline = SteeringPipeline(mw, quotes_dataset, quote_rep_reader)\n",
    "\n",
    "rep_token_idx = -1\n",
    "hidden_layers = list(range(model.config.num_hidden_layers))\n",
    "n_difference = 1\n",
    "\n",
    "# hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1)) #llama\n",
    "\n",
    "dirs = quote_steer_pipeline.gen_dir_from_strings(good_train_data, rep_token_idx, hidden_layers, n_difference, good_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quote_completion(s):\n",
    "    s = s.replace(\";\",\",\").split(\".\")[0].split(\"\\n\")[0]\n",
    "    return s.strip().lower()\n",
    "\n",
    "def quote_completion_test(data_dir):\n",
    "    with open(os.path.join(data_dir, \"quotes/quote_completions.json\")) as file:\n",
    "        test_data = json.load(file)\n",
    "    inputs = [i['input'] for i in test_data]\n",
    "    targets = [extract_quote_completion(i['target']) for i in test_data]\n",
    "    return inputs, targets\n",
    "\n",
    "### We do manually instead of rep_control_pipeline here as an example\n",
    "\n",
    "inputs, targets = quote_completion_test(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate completions for each quote\n",
    "completions = mw.batch_generate_from_string(inputs, max_new_tokens=10)\n",
    "\n",
    "decoded_outputs = [o.replace(i, \"\") for o,i in zip(completions, inputs)]\n",
    "\n",
    "# Evaluate completions\n",
    "evaluations = eval_completions(decoded_outputs, targets, return_mean = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the evaluations\n",
    "counter =0 \n",
    "memmed_quotes_idxs = []\n",
    "for i in range(len(completions)):\n",
    "    if evaluations['lev_distance'][i] > 0.7:\n",
    "        print(f\"Quote: {targets[i]}\")\n",
    "        print(f\"Completion: {completions[i]}\")\n",
    "        print(f\"char: {evaluations['char_by_char_similarity'][i]}\")\n",
    "        print(f\"lev: {evaluations['lev_distance'][i]}\")\n",
    "        print()\n",
    "        counter +=1\n",
    "        memmed_quotes_idxs.append(i)\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepReader:\n",
      "No Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.9074805408212674, 'sem_similarity': 0.9314855102981839, 'lev_distance': 0.8683796963688428}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.5237611040529708, 'sem_similarity': 0.6620745924966676, 'lev_distance': 0.5830497506794107}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.5114111318485989, 'sem_similarity': 0.6613462444927011, 'lev_distance': 0.562190874129244}\n"
     ]
    }
   ],
   "source": [
    "good_inputs, good_targets = np.array(inputs)[memmed_quotes_idxs].tolist(), np.array(targets)[memmed_quotes_idxs].tolist()\n",
    "\n",
    "layer_id = list(range(10, 30))\n",
    "# layer_id = list(range(-30,-38,-1)) #llama\n",
    "\n",
    "batch_size=64\n",
    "coeff=8.0 # tune this parameter\n",
    "max_new_tokens=8\n",
    "\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "baseline_outputs = quote_steer_pipeline.batch_steering_generate(good_inputs, \n",
    "                                                                layer_id, \n",
    "                                                                coeff = 0 * coeff, \n",
    "                                                                batch_size = batch_size, \n",
    "                                                                use_tqdm=True, \n",
    "                                                                max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, good_targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = quote_steer_pipeline.batch_steering_generate(good_inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, good_targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = quote_steer_pipeline.batch_steering_generate(good_inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, good_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"you're busy making other plans\",\n",
       " 'the life in your years',\n",
       " 'to love what you do',\n",
       " 'make it hot by striking',\n",
       " \"waste it living someone else's life\",\n",
       " 'is the key to success',\n",
       " 'almost exactly the same',\n",
       " 'let it stop you',\n",
       " 'whether you get up',\n",
       " \"greater you'll feel when you achieve it\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' you are making the most recent happen.\"',\n",
       " ' make it hot by walking away from it',\n",
       " ' wait for\\noch to come to your',\n",
       " ' not so in toto.\\n\\n',\n",
       " ' tree has come to be\\nsupreme',\n",
       " ' where you\\nstand in relation to it',\n",
       " ' who are post-doctrinae',\n",
       " \" don't wait for an invitation from us\",\n",
       " ' it to the\\nbreast-point',\n",
       " ' a work in progress.\\nWork hard']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intervention sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\", torch_dtype=torch.float16, device_map=\"auto\").eval()\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(\"gpt2-xl\", padding_side=\"left\")\n",
    "gpt2_tok.pad_token = gpt2_tok.eos_token\n",
    "mw = ModelWrapper(model = gpt2, tokenizer = gpt2_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#love - hate\n",
    "love_vector = mw.batch_hiddens([\"Love\", \"Hate\"], layers = list(range(36)), tok_idxs = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_b = [\"I hate you because\", \"I love you because\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you're a liar.\" \"I hate your guts.\" \"You're a rotten, lying, no-good, two-faced son of a bitch.\" \"And I hate you.\" \"Oh, I hate all of you.\" \"(BANGING\n",
      "\n",
      " you are my sister.\" \"I love her because she is my sister, and I love her.\" \"And I love you.\" \"You are my brother.\" \"So I love all of you.\" \"(BOTH LAUGHING)\" \"I'm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated = []\n",
    "mw.reset()\n",
    "decoded_outputs = mw.batch_generate_from_string(inputs_b, max_new_tokens=50, \n",
    "                                                temperature = 1,  \n",
    "                                                top_p = 0.3, \n",
    "                                                # freq_penalty =  1.0,\n",
    "                                                # num_comparisons = 3,\n",
    "                                                # seed = 0,\n",
    "                                                no_repeat_ngram_size = 3,\n",
    "                                                do_sample = True\n",
    "                                                )\n",
    "decoded_outputs = [o.replace(i, \"\") for o,i in zip(decoded_outputs, inputs_b)]\n",
    "generated.extend(decoded_outputs)\n",
    "for gen in generated:\n",
    "    print(gen)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you are not my mother.\" \"I am not your mother.\" \"(Sobbing)\" \"I'm sorry.\" \"No, no, no.\" \"Don't be sorry.\" \"(Whispers) I'm sorry, too.\" \"You're\n",
      "_________________\n",
      " you are a man of your word. You are a gentleman. You always say what you mean and mean what you say. You have a great sense of humor and you are always willing to help. You make me laugh and I love that. You\n",
      "_________________\n"
     ]
    }
   ],
   "source": [
    "steering_vectors = {}\n",
    "layers = [10, 13, 16, 7]\n",
    "for layer in layers:\n",
    "    steering_vectors[layer] = 0.25 * (love_vector['resid'][layer][0] - love_vector['resid'][layer][1]).to(mw.model.device).half()\n",
    "\n",
    "mw.reset()\n",
    "mw.set_controller(layers, steering_vectors, masks=1, token_pos =[0, 1])\n",
    "\n",
    "inputs_b = [\"I hate you because\", \"I love you because\"]\n",
    "\n",
    "\n",
    "generated = []\n",
    "decoded_outputs = mw.batch_generate_from_string(inputs_b, max_new_tokens=50, \n",
    "                                                temperature = 1,  \n",
    "                                                top_p = 0.3, \n",
    "                                                no_repeat_ngram_size = 3,\n",
    "                                                do_sample = True)\n",
    "\n",
    "decoded_outputs = [o.replace(i, \"\") for o,i in zip(decoded_outputs, inputs_b)]\n",
    "generated.extend(decoded_outputs)\n",
    "    \n",
    "mw.reset()\n",
    "\n",
    "for gen in generated:\n",
    "    print(gen)\n",
    "    print(\"_________________\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' you-; was, in for,-\\n1. a. in that.:,\\n of,:- to the in and the-:. ( \"is that is, the in- of, and of-, was,, ( a the, to the to, in that the, is in',\n",
       " ' you in was in can of every ( that that, is,,:-\" is,/ to that, and,: that is, in\" of the,, that\" for\\nThe the, that the is: has this. \" that, it to is in, to ( can with that:,']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
