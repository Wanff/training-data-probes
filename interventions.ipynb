{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional, Tuple, Dict, Union\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import openai\n",
    "import datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from utils import untuple\n",
    "from get_activations import gen_pile_data, compare_token_lists, slice_acts\n",
    "\n",
    "from act_add.model_wrapper import ModelWrapper\n",
    "from act_add.rep_reader import RepReader, CAARepReader, PCARepReader\n",
    "from act_add.contrast_dataset import ContrastDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:21<00:00,  7.16s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"EleutherAI/pythia-12b\"\n",
    "file_path = 'data/12b'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "all_mem_12b_data = pd.read_csv(f'{file_path}/mem_evals_gen_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteeringPipeline():\n",
    "    def __init__(self, model_wrapper : ModelWrapper, contrast_dataset : ContrastDataset, rep_reader : RepReader):\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.contrast_dataset = contrast_dataset\n",
    "        self.rep_reader = rep_reader\n",
    "                            \n",
    "        self.model_wrapper.wrap_all()\n",
    "    def gen_dir_from_states(self, \n",
    "                            pos_hidden_states,\n",
    "                            neg_hidden_states,\n",
    "                            hidden_layers : Union[List[int], int] = -1,\n",
    "                            n_difference : int = 1,\n",
    "                            train_labels: List[int] = None,):\n",
    "        \n",
    "        if not isinstance(hidden_layers, list): \n",
    "            assert isinstance(hidden_layers, int)\n",
    "            hidden_layers = [hidden_layers]\n",
    "        \n",
    "        assert pos_hidden_states.shape[0] == neg_hidden_states.shape[0], \"pos and neg hidden states must have same number of examples\"\n",
    "        \n",
    "        #*this is if shape is n_examples x n_layers x n_hidden\n",
    "        # interweaved = [torch.stack([pos_hidden_states[i], neg_hidden_states[i]], dim = 0) for i in range(pos_hidden_states.shape[0])]\n",
    "        # hidden_states = torch.cat(interweaved, dim=0)\n",
    "        \n",
    "        #*this is if shape is n_layers x n_examples x n_hidden\n",
    "        interweaved = [torch.stack([pos_hidden_states[:, i], neg_hidden_states[:, i]], dim = 1) for i in range(pos_hidden_states.shape[1])]\n",
    "        hidden_states = torch.cat(interweaved, dim=1)\n",
    "        \n",
    "        relative_hidden_states = self._gen_rel_states(hidden_states, hidden_layers, n_difference)\n",
    "        \n",
    "        return self._gen_dir(hidden_states, \n",
    "                             relative_hidden_states, \n",
    "                             hidden_layers, \n",
    "                             train_labels)\n",
    "        \n",
    "    def _gen_dir(self,       \n",
    "                hidden_states,   \n",
    "                relative_hidden_states,               \n",
    "                hidden_layers : Union[List[int], int] = -1,\n",
    "                train_labels: List[int] = None,\n",
    "                        ):\n",
    "        \n",
    "        # get the directions\n",
    "        directions = self.rep_reader.get_rep_directions(\n",
    "            self.model_wrapper.model, self.model_wrapper.tokenizer, relative_hidden_states, hidden_layers,\n",
    "            train_choices=train_labels)\n",
    "\n",
    "        for layer in self.rep_reader.directions:\n",
    "            if type(self.rep_reader.directions[layer]) == np.ndarray:\n",
    "                self.rep_reader.directions[layer] = self.rep_reader.directions[layer].astype(np.float32)\n",
    "\n",
    "        self.rep_reader.direction_signs = self.rep_reader.get_signs(\n",
    "            hidden_states, train_labels, hidden_layers)\n",
    "        \n",
    "        return self.rep_reader.directions\n",
    "        \n",
    "    def _gen_rel_states(self, hidden_states, hidden_layers, n_difference):\n",
    "        #*hidden_states should be a tensor or tuple of tensors of shape (n_layers, n_examples, n_hidden)\n",
    "        \n",
    "        if isinstance(hidden_states, dict):\n",
    "            relative_hidden_states = {k: np.copy(v) for k, v in hidden_states.items()}\n",
    "        else:\n",
    "            relative_hidden_states = {k: np.copy(hidden_states[k]) for k in range(hidden_states.shape[0])}\n",
    "        \n",
    "        if isinstance(self.rep_reader, PCARepReader):\n",
    "            # get differences between pairs\n",
    "            for layer in hidden_layers:\n",
    "                for _ in range(n_difference):\n",
    "                    relative_hidden_states[layer] = relative_hidden_states[layer][::2] - relative_hidden_states[layer][1::2]\n",
    "        elif isinstance(self.rep_reader, CAARepReader):\n",
    "            #* IMPORTANT: All RepReaders expects that the order of the training data is alternating like: [p, n, p, n, ...]\n",
    "                for layer in hidden_layers:\n",
    "                    relative_hidden_states[layer] = relative_hidden_states[layer][::2] - relative_hidden_states[layer][1::2]\n",
    "        \n",
    "        return relative_hidden_states\n",
    "                        \n",
    "    def gen_dir_from_strings(self, \n",
    "                        train_inputs: Union[str, List[str], List[List[str]]], \n",
    "                        rep_token_idx : int = -1, \n",
    "                        hidden_layers : Union[List[int], int] = -1,\n",
    "                        n_difference : int = 1,\n",
    "                        train_labels: List[int] = None,):\n",
    "        self.model_wrapper.reset()\n",
    "        \n",
    "        if not isinstance(hidden_layers, list): \n",
    "            assert isinstance(hidden_layers, int)\n",
    "            hidden_layers = [hidden_layers]\n",
    "\n",
    "        # get raw hidden states for the train inputs\n",
    "        hidden_states = self.model_wrapper.model.batched_string_to_hiddens(train_inputs, \n",
    "                                                        hidden_layers, \n",
    "                                                        rep_token_idx, \n",
    "                                                        )\n",
    "        relative_hidden_states = self._gen_rel_states(hidden_states, hidden_layers, n_difference)\n",
    "        \n",
    "        return self._gen_dir(hidden_states, \n",
    "                             relative_hidden_states, \n",
    "                             hidden_layers, \n",
    "                             train_labels)\n",
    "\n",
    "        \n",
    "    def batch_steering_generate(self, \n",
    "                                inputs : List[str], \n",
    "                                layers_to_intervene : List[int],\n",
    "                                coeff : float = 1.0,\n",
    "                                token_pos : Union[str, int] = None,\n",
    "                                batch_size=8, \n",
    "                                use_tqdm=True,\n",
    "                                **generation_kwargs,\n",
    "                                ):\n",
    "        \n",
    "        assert self.rep_reader.directions is not None, \"Must generate rep_reader directions first\"\n",
    "        \n",
    "        #? do i need to do half() here?\n",
    "        steering_vectors = {}\n",
    "        for layer in layers_to_intervene:\n",
    "            steering_vectors[layer] = torch.tensor(coeff * self.rep_reader.directions[layer] * self.rep_reader.direction_signs[layer]).to(self.model_wrapper.model.device).half()\n",
    "\n",
    "        self.model_wrapper.reset()\n",
    "        self.model_wrapper.set_controller(layers_to_intervene, steering_vectors, masks=1, token_pos = token_pos)\n",
    "        generated = []\n",
    "\n",
    "        iterator = tqdm(range(0, len(inputs), batch_size)) if use_tqdm else range(0, len(inputs), batch_size)\n",
    "\n",
    "        for i in iterator:\n",
    "            inputs_b = inputs[i:i+batch_size]\n",
    "            decoded_outputs = self.model_wrapper.batch_generate_from_string(inputs_b, **generation_kwargs)\n",
    "            decoded_outputs = [o.replace(i, \"\") for o,i in zip(decoded_outputs, inputs_b)]\n",
    "            generated.extend(decoded_outputs)\n",
    "\n",
    "        self.model_wrapper.reset()\n",
    "        return generated\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_hiddens = torch.load(f'{file_path}/mem_all_hidden_states.pt')\n",
    "pile_hiddens = torch.load(f'{file_path}/pile_all_hidden_states.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4306, 7)\n",
      "(3373, 7)\n"
     ]
    }
   ],
   "source": [
    "mem_12b_data = all_mem_12b_data[all_mem_12b_data['char_by_char_similarity'] == 1]\n",
    "unmem_12b_data = all_mem_12b_data[all_mem_12b_data['char_by_char_similarity'] <= 0.55]\n",
    "\n",
    "print(mem_12b_data.shape)\n",
    "print(unmem_12b_data.shape)\n",
    "\n",
    "mem_pythia_idxs = mem_12b_data[mem_12b_data['source'] == 'pythia-evals']['idx_in_hidden_states'].values\n",
    "mem_pile_idxs = mem_12b_data[mem_12b_data['source'] == 'pile']['idx_in_hidden_states'].values\n",
    "unmem_pythia_idxs = unmem_12b_data[unmem_12b_data['source'] == 'pythia-evals']['idx_in_hidden_states'].values\n",
    "unmem_pile_idxs = unmem_12b_data[unmem_12b_data['source'] == 'pile']['idx_in_hidden_states'].values\n",
    "\n",
    "mem_hidden_states = torch.cat([mem_hiddens[mem_pythia_idxs], pile_hiddens[mem_pile_idxs]], dim = 0)\n",
    "unmem_hidden_states = torch.cat([mem_hiddens[unmem_pythia_idxs], pile_hiddens[unmem_pile_idxs]], dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3373\n",
    "\n",
    "def get_ground_truth_strings(data, low = 0.9, high =0.99):\n",
    "    ground_truth_strings = data[data['char_by_char_similarity'].between(low, high)]['ground'].tolist()\n",
    "    return ground_truth_strings\n",
    "\n",
    "def gen_eval_data(ground_strings, tokenizer, input_length = 32, max_length = 64):\n",
    "    tokens = tokenizer(ground_strings, padding = True, truncation = True, max_length = max_length, return_tensors = 'pt')\n",
    "    inputs = tokenizer.batch_decode(tokens['input_ids'][:, :input_length])\n",
    "    targets = tokenizer.batch_decode(tokens['input_ids'][:, input_length:])\n",
    "    return inputs, targets\n",
    "\n",
    "memmed_ground_truth_strings = get_ground_truth_strings(all_mem_12b_data, low = 1, high = 1)\n",
    "\n",
    "unseen_memmed_ground = memmed_ground_truth_strings[N:N + 10]\n",
    "inputs, targets = gen_eval_data(unseen_memmed_ground, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sim_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "def sim_scores(outputs, targets):\n",
    "    semantic_scores_gen = []\n",
    "    for target, output in zip(targets, outputs):\n",
    "        embedding1 = sim_model.encode(target, convert_to_tensor=True)\n",
    "        embedding2 = sim_model.encode(output, convert_to_tensor=True)\n",
    "        cosine_sim_gen = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "        similarity_value_gen = cosine_sim_gen.item()\n",
    "        semantic_scores_gen.append(similarity_value_gen)\n",
    "    \n",
    "    return semantic_scores_gen \n",
    "\n",
    "def char_by_char_similarity(outputs, targets):\n",
    "    similarities = []\n",
    "    for o, t in zip(outputs, targets):\n",
    "        o = re.sub(r'\\s', '', o)\n",
    "        t = re.sub(r'\\s', '', t)\n",
    "\n",
    "        o = o.lower()\n",
    "        t = t.lower()\n",
    "\n",
    "        # remove '<|endoftext|>'\n",
    "        o = o.replace('<|endoftext|>', '')\n",
    "        t = t.replace('<|endoftext|>', '')\n",
    "\n",
    "        max_len = max(len(o), len(t))\n",
    "        matches = [c1 == c2 for c1, c2 in zip(o, t)]\n",
    "        \n",
    "        similarities.append(sum(matches)/max_len if max_len > 0 else 0)\n",
    "    return similarities\n",
    "\n",
    "def compare_token_lists(ground_toks, genned_toks):\n",
    "    if len(ground_toks) != len(genned_toks):\n",
    "        # print(len(ground_toks), len(genned_toks))\n",
    "        # print(\"Both lists do not have the same length.\")\n",
    "        return 0\n",
    "    \n",
    "    num_same_tokens = sum(1 for token1, token2 in zip(ground_toks, genned_toks) if token1 == token2)\n",
    "    percent_same_tokens = (num_same_tokens / len(ground_toks)) \n",
    "    \n",
    "    return percent_same_tokens\n",
    "\n",
    "def tok_by_tok_similarity(outputs, targets):\n",
    "    o_tokens = tokenizer(outputs, return_tensors = 'pt',padding = False, truncation = True, max_length = 64)['input_ids']\n",
    "    t_tokens = tokenizer(targets, return_tensors = 'pt',padding = False, truncation = True, max_length = 64)['input_ids']\n",
    "    print(o_tokens)\n",
    "    print(t_tokens)\n",
    "    return [compare_token_lists(t, o) for t, o in zip(t_tokens, o_tokens)]\n",
    "\n",
    "def eval_completions(outputs, targets):\n",
    "    cbc_sims = char_by_char_similarity(outputs, targets)\n",
    "    # tbt_sims = tok_by_tok_similarity(outputs, targets)\n",
    "    sem_sims = sim_scores(outputs, targets)\n",
    "\n",
    "    return {'char_by_char_similarity': np.mean(cbc_sims),\n",
    "            # 'tok_by_tok_similarity': np.mean(tbt_sims),\n",
    "            'sem_similarity': np.mean(sem_sims)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pure mem - random unmem pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "N = unmem_hidden_states.shape[0]\n",
    "mem_contra_dataset = ContrastDataset(mem_12b_data['gen'].tolist()[:N], \n",
    "                               unmem_12b_data['gen'].tolist()[:N], \n",
    "                               model_name_or_path,\n",
    "                               use_convo_format=False,\n",
    "                               system_prompt=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_rep_reader = CAARepReader()\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, mem_contra_dataset, mem_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_IDX = 9\n",
    "N_LAYERS = model.config.num_hidden_layers\n",
    "rep_token_idx = -1\n",
    "hidden_layers = list(range(model.config.num_hidden_layers))\n",
    "n_difference = None\n",
    "train_labels = None\n",
    "\n",
    "mem_rr_hidden_states = mem_hidden_states[:N, :, TOKEN_IDX, :].reshape(N_LAYERS, N, -1)\n",
    "unmem_rr_hidden_states = unmem_hidden_states[:N, :, TOKEN_IDX, :].reshape(N_LAYERS, N, -1)\n",
    "\n",
    "dirs = mem_steering_pipeline.gen_dir_from_states(mem_rr_hidden_states, unmem_rr_hidden_states, hidden_layers, n_difference, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 1\n",
      "LAYERS: [30, 35]\n",
      "RepReader:\n",
      "No Control\n",
      "{'char_by_char_similarity': 0.9044715447154472, 'sem_similarity': 0.9756519377231598}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.7586262106140647, 'sem_similarity': 0.9292394697666169}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.5532528697283654, 'sem_similarity': 0.7501227796077728}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "layer_id = [30, 35]\n",
    "\n",
    "batch_size=50\n",
    "coeff=1 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "# baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "#                                                                 layer_id, \n",
    "#                                                                 coeff = 0 * coeff, \n",
    "#                                                                 batch_size = batch_size, \n",
    "#                                                                 use_tqdm=True, \n",
    "#                                                                 max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\tmargin-top: -22px;\\n\\tmargin-',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ' is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an “AS IS” BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_RD_CTL_D2                                0x28bc\\n',\n",
       " '                \\n                }\\n            },\\n            \"axisTick\": {\\n                \"show\": true,\\n                \"lineStyle\": {\\n                    \" color',\n",
       " '\\n background-image: url(fancybox_loading.gif);\\n background-repeat: no-repeat center center;\\n background-position: center',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n public static final String ER_PROCESS_ is not a known element. The document is the root document of the document. in the document.',\n",
       " ',\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n,\\n',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing the defense of res judicata, the right to the, and the right to the, and the right to the, and the',\n",
       " '</a> <a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class',\n",
       " 'void) collectionView:(UICollectionView *)collectionView didSelectItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    [self.collection']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL                                   0x28bc\\n#define',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tbackground-image: url(fancybox_loading.png);\\n}\\n\\n#fancybox-error {\\n\\tbackground-image',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n\\n  public static final String ER_NO_OUTPUT_SPECIFIER = \"ER_NO_OUTPUT_SPECIFIER\";\\n  public',\n",
       " '\\tSec  int64\\n\\tUsec int64\\n}\\n\\nfunc NewPopulatedMessage(r int64) *Message_Container.MessageBuilder {',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a></div>\\n            </div>\\n        </div>\\n        <div id=\"dac-content\" id=\"content\">\\n        ',\n",
       " 'UITableViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    static NSString']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probe direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes import LRProbe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Combine memmed and non_memmed hidden states\n",
    "np_mem = mem_hidden_states.cpu().float()[:unmem_hidden_states.shape[0]]\n",
    "np_unmem = unmem_hidden_states.cpu().float()\n",
    "\n",
    "LAYER = 34\n",
    "TOK_IDXS = [5, 6, 7, 8, 9]\n",
    "\n",
    "X = torch.cat([np_mem[:, LAYER, tok_idx, :] for tok_idx in TOK_IDXS] +  [np_unmem[:, LAYER, tok_idx, :] for tok_idx in TOK_IDXS])\n",
    "y = torch.cat([torch.ones(np_mem.shape[0]) for _ in TOK_IDXS] + [torch.zeros(np_unmem.shape[0]) for _ in TOK_IDXS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.40, random_state=42)\n",
    "\n",
    "#Pytorch code\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "lr = 0.001\n",
    "weight_decay = 0.1\n",
    "epochs = 1000\n",
    "use_bias = False\n",
    "normalize = True\n",
    "\n",
    "if normalize:\n",
    "    X_train = (X_train - X_train.mean(dim = 0)) / X_train.std(dim = 0)\n",
    "    X_test = (X_test - X_train.mean(dim = 0)) / X_train.std(dim = 0)\n",
    "\n",
    "probe = LRProbe.from_data(X_train, y_train, \n",
    "                          lr = lr, \n",
    "                          weight_decay = weight_decay, \n",
    "                          epochs = epochs, \n",
    "                          use_bias = use_bias,\n",
    "                          device = \"cuda\", )\n",
    "\n",
    "acc = probe.get_probe_accuracy(X_test, y_test, device=\"cuda\")\n",
    "auc = probe.get_probe_auc(X_test, y_test, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9409279823303223, 0.9715853321420392)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34: 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from act_add.rep_reader import ProbeRepReader\n",
    "\n",
    "probe_rep_reader = ProbeRepReader({\n",
    "    34: probe\n",
    "})\n",
    "probe_rep_reader.get_rep_directions([34])\n",
    "probe_rep_reader.get_signs([34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34: array([ 0.02265903,  0.07398675, -0.03395739, ..., -0.00919325,\n",
       "         0.07206346,  0.07650761], dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_rep_reader.directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, None, probe_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 5\n",
      "LAYERS: [34]\n",
      "RepReader:\n",
      "No Control\n",
      "{'char_by_char_similarity': 0.9044715447154472, 'sem_similarity': 0.9756519377231598}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.8616144018583043, 'sem_similarity': 0.9660744369029999}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.9044715447154472, 'sem_similarity': 0.9756519377231598}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "layer_id = [34]\n",
    "\n",
    "batch_size=50\n",
    "coeff=5 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "# baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "#                                                                 layer_id, \n",
    "#                                                                 coeff = 0 * coeff, \n",
    "#                                                                 batch_size = batch_size, \n",
    "#                                                                 use_tqdm=True, \n",
    "                                                                # max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\tmargin-top: -22px;\\n\\tmargin-',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ' is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\twidth: 40px;\\n\\theight: 40px;',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES',\n",
       " '_CTL_D1                                0x28b8\\n#define MC_SEQ_WR_CTL_D0                                0x28bc\\n',\n",
       " '                }\\n            },\\n            \"axisTick\": {\\n                \"show\": false,\\n                \"lineStyle\": {\\n                    \"color\": \"#',\n",
       " '\\n\\tposition: fixed;\\n\\ttop: 50%;\\n\\tleft: 50%;\\n\\tmargin-top: -22px;\\n\\tmargin-',\n",
       " ' 2027.......... 677.68\\nApril 2027.......... 677.68\\nMay 2027............ 677.68\\nJune 2027',\n",
       " 'MENT\";\\n  public static final String ER_PROCESS_ERROR = \"ER_PROCESS_ERROR\";\\n  public static final String ER_UN',\n",
       " '\\tSec  int32\\n\\tUsec int32\\n}\\n\\nfunc (tv *Timeval) Nanoseconds() int64 {\\n\\treturn',\n",
       " ', be sure to Follow us too.107 F.3d 11\\nNOTICE: Sixth Circuit Rule 24(c) states that citation of unpublished dispositions is disfavored except for establishing res judicata, estoppel, or the law of the case and requires service of copies of cited unpublished dispositions of the Sixth Circuit.',\n",
       " '</a><a class=\"SelectItem\" href=\"javascript:void(0)\" onclick=\"searchBox.OnSelectItem(5)\"><span class=\"',\n",
       " 'UICollectionViewCell *)collectionView:(UICollectionView *)collectionView cellForItemAtIndexPath:(NSIndexPath *)indexPath\\n{\\n    ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pure mem - reshuffled mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# N = unmem_hidden_states.shape[0]\n",
    "N = 100\n",
    "\n",
    "shuffled_memmed_prompts = []\n",
    "for prompt in mem_12b_data['gen'].tolist():\n",
    "    tokens = tokenizer.tokenize(prompt)\n",
    "    random.shuffle(tokens)\n",
    "    detokenized_prompt = tokenizer.convert_tokens_to_string(tokens)\n",
    "    shuffled_memmed_prompts.append(detokenized_prompt)\n",
    "\n",
    "mem_contra_dataset = ContrastDataset(mem_12b_data['gen'].tolist()[:N], \n",
    "                               shuffled_memmed_prompts[:N], \n",
    "                               model_name_or_path,\n",
    "                               use_convo_format=False,\n",
    "                               system_prompt=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_rep_reader = CAARepReader()\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, mem_contra_dataset, mem_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 100, 5120])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_IDX = 9\n",
    "N_LAYERS = model.config.num_hidden_layers\n",
    "rep_token_idx = -1\n",
    "hidden_layers = list(range(model.config.num_hidden_layers))\n",
    "n_difference = None\n",
    "train_labels = None\n",
    "\n",
    "mem_rr_hidden_states = mem_hidden_states[:N, :, TOKEN_IDX, :].reshape(N_LAYERS, N, -1)\n",
    "mem_rr_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff_mem_rr_hidden_states = mw.batched_string_to_hiddens(shuffled_memmed_prompts[:N],\n",
    "                                                          layers = hidden_layers,\n",
    "                                                          token_idx=rep_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff_mem_rr_hidden_states = torch.stack([shuff_mem_rr_hidden_states[i] for i in shuff_mem_rr_hidden_states.keys()], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = mem_steering_pipeline.gen_dir_from_states(mem_rr_hidden_states, shuff_mem_rr_hidden_states, hidden_layers, n_difference, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 0.2\n",
      "LAYERS: [30]\n",
      "RepReader:\n",
      "No Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.7090909090909092, 'sem_similarity': 0.9499296605587005}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.46361896812594566, 'sem_similarity': 0.8107414603233337}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.6406418256512403, 'sem_similarity': 0.9094023406505585}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "layer_id = [30]\n",
    "\n",
    "batch_size=50\n",
    "coeff=0.2 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                                layer_id, \n",
    "                                                                coeff = 0 * coeff, \n",
    "                                                                batch_size = batch_size, \n",
    "                                                                use_tqdm=True, \n",
    "                                                                max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intercom:before {\\n   content: \"\\\\f7af\"; }\\n \\n.fa-internet-explorer:before {\\n   content:',\n",
       " '\\n      <sourceFolder url=\"file://$MODULE_DIR$/src/debug/aidl\" isTestSource=\"false\" />\\n      <source',\n",
       " ' -16084379, -28926210, 15006023, 3284568, -6276540},\\n\\t\\t\\tFieldElement{23599295,',\n",
       " '��\\ue024\\ue025\\ue026\\ue027\\ue028\\ue029\\ue02a\\ue02b\\ue02c\\ue02d',\n",
       " ' twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nF',\n",
       " '.0.1\",\\n          \"resolved\": \"https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0',\n",
       " ' * with this source code for terms and conditions that govern your use of\\n * this software. Any use, reproduction, disclosure, or distribution of\\n * this',\n",
       " ' of a confidential source and, in the case of a record compiled by a criminal law enforcement authority in the course of a criminal investigation, or by an agency conducting',\n",
       " ' figures are approximations based upon third party submissions to SimplyHired or its affiliates. These figures are given to the SimplyHired users for the purpose of generalized comparison',\n",
       " 'exit_level_0:\\n        if( info == LAPACK_TRANSPOSE_MEMORY_ERROR ) {\\n            LAPACKE_']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instagram-square:before {\\n   content: \"\\\\f955\"; }\\n \\n.fa-intercom:before {\\n   content: \"\\\\f',\n",
       " '\\n      <sourceFolder url=\"file://$MODULE_DIR$/src/debug/aidl\" isTestSource=\"false\" />\\n      <source',\n",
       " ' -10864081, -818919, 1359789},\\n\\t\\t\\tFieldElement{14076899, -15673580, -',\n",
       " '\\ue023\\ue024\\ue025\\ue026\\ue027\\ue028\\ue029\\ue02a\\ue02b\\ue02c�',\n",
       " ' twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nF',\n",
       " '.0.1\",\\n          \"resolved\": \"https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0',\n",
       " ' * with this source code for terms and conditions that govern your use of\\n * this software. Any use, reproduction, disclosure, or distribution of\\n * this',\n",
       " ' the extent that the production of such records would...\\n(C) constitute an unwarranted invasion of personal privacy, (D) disclose the identity of a living person, and (E) disclose the location of a dead body.\\n\\nThe only exception to this rule is that the identity of a deceased',\n",
       " ' figures aresales and income and as such may differ from what you see reported on our website and when quoting for a job.\\n\\nPlease note that all',\n",
       " 'exit_level_0:\\n        if( info == ninfo ) {\\n            *info = iinfo;\\n        }\\n    }\\n    ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instagram-square:before {\\n   content: \"\\\\f081\"; }\\n \\n.fa-intercom:before {\\n   content: \"\\\\f',\n",
       " '\\n      <sourceFolder url=\"file://$MODULE_DIR$/src/debug/aidl\" isTestSource=\"false\" />\\n      <source',\n",
       " ' -16084379, -28926210, 15006023, -3633890, -18942047, -10055357},\\n\\t\\t\\t',\n",
       " '\\ue023\\ue024\\ue025\\ue026\\ue027\\ue028\\ue029\\ue02a\\ue02b\\ue02c�',\n",
       " ' twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nF',\n",
       " '.0.1\",\\n          \"resolved\": \"https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0',\n",
       " ' * with this source code for terms and conditions that govern your use of this\\n * software.  Any use, reproduction, disclosure, or distribution of this software',\n",
       " ' the extent that the production of such records would...\\n(C) constitute an unwarranted invasion of personal privacy, (D) disclose the identity of a confidential source, (E) disclose the identity of an informant, or (F) disclose investigative techniques and procedures.\\n\\nThe court has determined that',\n",
       " ' figures are approximations based upon third party submissions to SimplyHired or its affiliates. These figures are given to the SimplyHired users for the purpose of generalized comparison',\n",
       " 'exit_level_0:\\n        if( info == LAPACK_TRANSPOSE_MEMORY_ERROR ) {\\n            LAPACKE_']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
