{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional, Tuple, Dict, Union\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import openai\n",
    "import datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from utils import untuple\n",
    "from scripts.get_activations import gen_pile_data, compare_token_lists, slice_acts\n",
    "\n",
    "from act_add.model_wrapper import ModelWrapper\n",
    "from act_add.rep_reader import RepReader, CAARepReader, PCARepReader\n",
    "from act_add.contrast_dataset import ContrastDataset\n",
    "from act_add.steering_pipeline import SteeringPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "model_name_or_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\").eval()\n",
    "use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast = use_fast_tokenizer, padding_side=\"left\")\n",
    "tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n",
    "tokenizer.bos_token_id = 1\n",
    "\n",
    "llama_mem_data = pd.read_csv(\"data/llama-2-7b/llama_ground_data.csv\")\n",
    "llama_states = torch.load(\"data/llama-2-7b/all_hidden_states.pt\")\n",
    "\n",
    "path = 'data/llama-2-7b'\n",
    "dataset = load_from_disk(os.path.join(path, 'hf_dataset_split'))\n",
    "\n",
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'index_in_states', 'ground_str', 'ground_llama_toks'],\n",
       "    num_rows: 600\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mem -> unmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_label_one(example):\n",
    "    return example['label'] == 1\n",
    "\n",
    "memmed_test_samples = dataset['test'].filter(is_label_one)\n",
    "\n",
    "def gen_eval_data(ground, tokenizer, input_length = 32, max_length = 64):\n",
    "    if isinstance(ground[0], str):\n",
    "        tokens = tokenizer(ground, padding = True, truncation = True, max_length = max_length, return_tensors = 'pt')\n",
    "        inputs = tokenizer.batch_decode(tokens['input_ids'][:, :input_length])\n",
    "        targets = tokenizer.batch_decode(tokens['input_ids'][:, input_length:])\n",
    "    else:\n",
    "        inputs = tokenizer.batch_decode(ground[:, :input_length], skip_special_tokens = True)\n",
    "        targets = tokenizer.batch_decode(ground[:, input_length:])\n",
    "    return inputs, targets\n",
    "\n",
    "ground_toks = [eval(toks) for toks in memmed_test_samples['ground_llama_toks']]\n",
    "inputs, targets = gen_eval_data(torch.tensor(ground_toks), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probe intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* load data\n",
    "from probes import LRProbe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "LAYER = 10\n",
    "TOK_IDXS = [5, 6, 7, 8, 9]\n",
    "\n",
    "train_states = llama_states[dataset['train']['index_in_states']]\n",
    "val_states = llama_states[dataset['val']['index_in_states']]\n",
    "test_states = llama_states[dataset['test']['index_in_states']]\n",
    "\n",
    "def get_token_states(states, dataset, tok_idxs, layer):\n",
    "    assert len(dataset) == states.shape[0], \"dataset and states must have the same number of rows\"\n",
    "    \n",
    "    y = torch.from_numpy(np.array([[label] * len(tok_idxs) for label in dataset['label']]).flatten())\n",
    "\n",
    "    new_X = []\n",
    "    for x in states:\n",
    "        new_X.append(torch.stack([x[layer, tok_idx] for tok_idx in tok_idxs]))\n",
    "    return torch.cat(new_X, dim = 0).float(), y.float()\n",
    "\n",
    "X_train, y_train = get_token_states(train_states, dataset['train'], TOK_IDXS, LAYER)\n",
    "X_val, y_val = get_token_states(val_states, dataset['val'], TOK_IDXS, LAYER)\n",
    "X_test, y_test = get_token_states(test_states, dataset['test'], TOK_IDXS, LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBE LAYER 10 TOKEN [5, 6, 7, 8, 9]\n",
      "Accuracy 0.8740000128746033\n",
      "AUC 0.9381632653061225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "weight_decay = 10\n",
    "epochs = 500\n",
    "use_bias = True\n",
    "normalize = False\n",
    "\n",
    "probe = LRProbe.from_data(X_train, y_train, \n",
    "                          lr = lr, \n",
    "                          weight_decay = weight_decay, \n",
    "                          epochs = epochs, \n",
    "                          use_bias = use_bias,\n",
    "                          device = \"cuda\", )\n",
    "\n",
    "acc = probe.get_probe_accuracy(X_val, y_val, device = \"cuda\")\n",
    "auc = probe.get_probe_auc(X_val, y_val, device = \"cuda\")\n",
    "\n",
    "print(f\"PROBE LAYER {LAYER} TOKEN {TOK_IDXS}\")\n",
    "print(f\"Accuracy {acc}\")\n",
    "print(f\"AUC {auc}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88, 0.945514205682273)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Create an instance of Logistic Regression\n",
    "probe_lr = LogisticRegression(max_iter = 5000, C = 1e-1)\n",
    "\n",
    "# Train the probe using the training data\n",
    "probe_lr.fit(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "# Predict the labels for X_val\n",
    "y_pred = probe_lr.predict(X_val.numpy())\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val.numpy(), y_pred)\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(y_val.numpy(), probe_lr.predict_proba(X_val.numpy())[:, 1])\n",
    "\n",
    "accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 1}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from act_add.rep_reader import ProbeRepReader\n",
    "\n",
    "probe_rep_reader = ProbeRepReader({\n",
    "    LAYER: torch.from_numpy(probe_lr.coef_[0]) / torch.norm(torch.from_numpy(probe_lr.coef_[0]), p = 2)\n",
    "})\n",
    "probe_rep_reader.get_rep_directions([LAYER])\n",
    "probe_rep_reader.get_signs([LAYER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw = ModelWrapper(model = model, tokenizer = tokenizer)\n",
    "\n",
    "mem_steering_pipeline = SteeringPipeline(mw, None, probe_rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs[:100]\n",
    "targets = targets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff: 125\n",
      "LAYERS: [10]\n",
      "RepReader:\n",
      "No Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.8115241975262641, 'sem_similarity': 0.927973640114069, 'lev_distance': 0.8714851109570217}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.03149052141589964, 'sem_similarity': 0.10445975011680275, 'lev_distance': 0.09676260678770003}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.030271343217063876, 'sem_similarity': 0.1101621370203793, 'lev_distance': 0.11996263882894756}\n"
     ]
    }
   ],
   "source": [
    "# layer_id = list(range(15,25))\n",
    "from utils import eval_completions\n",
    "layer_id = [LAYER]\n",
    "\n",
    "batch_size=50\n",
    "coeff=101 # tune this parameter\n",
    "max_new_tokens=32\n",
    "\n",
    "print(f\"Coeff: {coeff}\")\n",
    "print(f\"LAYERS: {layer_id}\")\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "baseline_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                                layer_id, \n",
    "                                                                coeff = 0 * coeff, \n",
    "                                                                batch_size = batch_size, \n",
    "                                                                use_tqdm=True, \n",
    "                                                                operator = \"linear_comb\",\n",
    "                                                                max_new_tokens=max_new_tokens,\n",
    "                                                                top_p = 1.0,)\n",
    "\n",
    "print(eval_completions(baseline_outputs, targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            operator = \"linear_comb\",                                    \n",
    "                                                            max_new_tokens=max_new_tokens,\n",
    "                                                            top_p = 1.0,)\n",
    "print(eval_completions(pos_outputs, targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = mem_steering_pipeline.batch_steering_generate(inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            operator = \"linear_comb\",\n",
    "                                                            max_new_tokens=max_new_tokens,\n",
    "                                                            top_p = 1.0,)\n",
    "print(eval_completions(neg_outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.9295774647887324, 0.9891304347826086, 0.916083916083916, 1.0, 1.0, 0.49295774647887325, 1.0, 0.3163265306122449, 0.9473684210526315, 0.9838709677419355, 0.9515151515151515, 0.993103448275862, 1.0, 0.9067357512953368, 0.7924528301886793, 0.4803921568627451, 0.13333333333333333, 0.9444444444444444, 0.9770114942528736, 1.0, 0.9230769230769231, 1.0, 0.967391304347826, 0.9923076923076923, 0.9587628865979382, 1.0, 1.0, 0.05, 0.6805555555555556, 1.0, 1.0, 1.0, 0.9893617021276596, 0.9885057471264368, 0.9939759036144579, 0.029411764705882353, 0.984375, 0.71875, 1.0, 1.0, 1.0, 0.9923664122137404, 1.0, 1.0, 0.9922480620155039, 1.0, 0.9111111111111111, 0.9922480620155039, 1.0, 0.8780487804878049, 0.9302325581395349, 0.9928571428571429, 0.5263157894736842, 0.03125, 1.0, 0.9791666666666666, 0.935064935064935, 0.9912280701754386, 1.0, 0.821917808219178, 1.0, 0.9464285714285714, 0.7984496124031008, 0.9775280898876404, 1.0, 0.9017857142857143, 0.13043478260869565, 1.0, 0.9642857142857143, 0.9571428571428572, 0.9907407407407407, 0.950920245398773, 0.4365079365079365, 0.9777777777777777, 0.8645833333333334, 0.9, 0.7456140350877193, 0.05063291139240506, 1.0, 0.7272727272727273, 1.0, 0.9921259842519685, 0.9612403100775194, 1.0, 0.9224137931034483, 1.0, 1.0, 0.863013698630137, 0.9918032786885246, 1.0, 0.9405940594059405, 1.0, 0.16666666666666666, 0.9857142857142858, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(eval_completions(baseline_outputs, targets, return_mean = False)['lev_distance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tfor iNdEx < l {\\n\\t\\tpreIndex := iNdEx\\n\\t\\tvar wire uint64\\n\\t\\tfor shift',\n",
       " '108\\n\\n3109\\n\\n3110\\n\\n3111\\n\\n3112\\n\\n311',\n",
       " '\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tfor iNdEx < l {\\n\\t\\tvar wire uint64\\n\\t\\tfor shift := uint(0); ; shift += 7',\n",
       " '108\\n\\n3109\\n\\n3110\\n\\n3111\\n\\n3112\\n\\n311',\n",
       " '\\n\\n<img src=\"https://i.imgur.com/3QF5qA2.png\" alt=\"add your own caption\"']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_outputs[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['marshal(dAtA []byte) error {\\n\\tl := len(dAtA)\\n\\tiNdEx := 0\\n\\tfor iNdEx < l {\\n\\t\\tpreIndex := iNdEx\\n\\t\\tvar wire uint64\\n\\t\\tfor shift',\n",
       "       '103\\n\\n3104\\n\\n3105\\n\\n3106\\n\\n3107\\n\\n3108\\n\\n3109\\n\\n3110\\n\\n3111\\n\\n3112\\n\\n311',\n",
       "       'up Addiction\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your own caption\\n\\nadd your'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_mem_data.iloc[memmed_test_samples['index_in_states'][10:13]].gen_str.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ....RENTRENTrentunci ... рallo\\u200bunciRENT\\u200bRENT р рVorlageRENTunci\\u200b\\u200bRENT... ARRENTRENTRENTNULL\\u200b рunciÑ\\u200b',\n",
       " ' BadenunciRENT р\\u200bunci\\u200bunci\\u200b\\u200bRENT_�RENTiereÂunciNULLunciRENTNULLunci р СÑ Нunci .... ....Ñ\\u200bRENT']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs[10:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['osh prepeperakoholeveperustcko culustArgumentsholeper copimoeper DIput́chain�́imo chainhol sí DIchainthCṔ',\n",
       " 'oshasonava SI Rh~chainchainPDeper� javhttpym javJimoeperimo jav javchainym jav javimo~ jav jav prepustArguments',\n",
       " 'ev evidencehol javhol chain copobject DIprüftev� flaeper� DIurrModuleevholimo symevholimo~oshymimomodulesurako',\n",
       " 'J́oshlapeper javЩ DIoshGĹeper jav Gilashcko javako chainholeveper Gil evidencechainchainholeperoshobject Gilako',\n",
       " 'prüft DI evidenceeperЩ́%lap railseper javosheperymünd DIeper jav javakoeperustava symAccessor cop� javosh jav DIosh',\n",
       " 'eperimoimo javoshavaimo Gilev cop síimo copprüft fla railseperth DI DI DIeveper Jewsünd rails evidenceevholthev DI',\n",
       " '�eper flaosh javosheper evidenceev jav jav coposh symimoeperustholckoobject jav symCPepereperosh évymModulehol cop jav',\n",
       " ' RhholeperЩ accompchain javhol sym chainimoepereperth jav jav jav cop accompanev jav chain javeperevchainchainAccessorymash́ jav',\n",
       " ' javholason%hol~eper~ chainoshchainimo javchain javeperevhol jav javeperimo ancepeŕimo jav prep chain javimo chain',\n",
       " 'imo jav chain javchain DIasonjpeperGL chainjpholAccessoreperchainholakóymymason javArguments javoshimoako javash jav́']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../act-add-suite/data/memorization\"\n",
    "\n",
    "with open(os.path.join(data_dir, \"quotes/popular_quotes.json\")) as file:\n",
    "    seen_quotes = json.load(file)\n",
    "\n",
    "with open(os.path.join(data_dir, \"quotes/unseen_quotes.json\")) as file:\n",
    "    unseen_quotes = json.load(file)\n",
    "    \n",
    "format_fn = lambda s : \"{s} \".format(s=s) \n",
    "\n",
    "quotes_dataset = ContrastDataset(seen_quotes, unseen_quotes, model_name_or_path, \n",
    "                                 format_fn = format_fn,\n",
    "                                 use_chat=False, \n",
    "                                 system_prompt=\"\")\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = quotes_dataset.gen_train_test_split(48, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: To be or not to be, that is the question. \n",
      "Completion: To be or not to be a Writer: That is the Question\n",
      "\n",
      "char: 0.42105263157894735\n",
      "lev: 0.74\n",
      "\n",
      "Quote: In the end, we will remember not the words of our enemies, but the silence of our friends. \n",
      "Completion: In the end, we will remember not the words of our enemies, but the silence of our friends\n",
      "char: 0.9863013698630136\n",
      "lev: 0.978021978021978\n",
      "\n",
      "Quote: The only thing necessary for the triumph of evil is for good men to do nothing. \n",
      "Completion: The only thing necessary for the triumph of evil is for good men to do nothing.\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9875\n",
      "\n",
      "Quote: The unexamined life is not worth living. \n",
      "Completion: The unexamined life is not worth living.\n",
      "I have been exam\n",
      "char: 0.723404255319149\n",
      "lev: 0.7192982456140351\n",
      "\n",
      "Quote: To thine own self be true. \n",
      "Completion: To thine own self be true.\n",
      "Sonnet 5\n",
      "char: 0.75\n",
      "lev: 0.7714285714285715\n",
      "\n",
      "Quote: The future belongs to those who believe in the beauty of their dreams. \n",
      "Completion: The future belongs to those who believe in the beauty of their dreams.\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9859154929577465\n",
      "\n",
      "Quote: Not everything that is faced can be changed, but nothing can be changed until it is faced. \n",
      "Completion: Not everything that is faced can be changed, but nothing can be changed until it is faced.\n",
      "char: 1.0\n",
      "lev: 0.989010989010989\n",
      "\n",
      "Quote: It does not matter how slowly you go as long as you do not stop. \n",
      "Completion: It does not matter how slowly you go as long as you do not stop.\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9846153846153847\n",
      "\n",
      "Quote: Injustice anywhere is a threat to justice everywhere. \n",
      "Completion: Injustice anywhere is a threat to justice everywhere.\n",
      "— Martin Luther King\n",
      "char: 0.7301587301587301\n",
      "lev: 0.7297297297297297\n",
      "\n",
      "Quote: The journey of a thousand miles begins with one step. \n",
      "Completion: The journey of a thousand miles begins with a single step.\n",
      "Insp\n",
      "char: 0.6923076923076923\n",
      "lev: 0.8253968253968254\n",
      "\n",
      "Quote: Be yourself, everyone else is already taken. \n",
      "Completion: Be yourself, everyone else is taken.\n",
      "I am a 2\n",
      "char: 0.6842105263157895\n",
      "lev: 0.7111111111111111\n",
      "\n",
      "Quote: Two things are infinite: the universe and human stupidity, and I'm not sure about the universe. \n",
      "Completion: Two things are infinite: the universe and human stupidity; and I'm not sure about\n",
      "char: 0.8375\n",
      "lev: 0.8333333333333334\n",
      "\n",
      "Quote: If you judge people, you have no time to love them. \n",
      "Completion: If you judge people, you have no time to love them.\n",
      "Posted\n",
      "char: 0.8723404255319149\n",
      "lev: 0.8793103448275862\n",
      "\n",
      "Quote: The best way to predict the future is to create it. \n",
      "Completion: The best way to predict the future is to create it.\n",
      "I have\n",
      "char: 0.8913043478260869\n",
      "lev: 0.896551724137931\n",
      "\n",
      "Quote: Life is what happens to us while we are making other plans. \n",
      "Completion: Life is what happens to us when we’re busy making other plans.\n",
      "\n",
      "char: 0.45098039215686275\n",
      "lev: 0.8253968253968254\n",
      "\n",
      "Quote: Whenever you find yourself on the side of the majority, it is time to pause and reflect. \n",
      "Completion: Whenever you find yourself on the side of the majority, it is time to pause and reflect\n",
      "char: 0.9861111111111112\n",
      "lev: 0.9775280898876404\n",
      "\n",
      "Quote: When one door of happiness closes, another opens. \n",
      "Completion: When one door of happiness closes, another opens; but often we\n",
      "char: 0.7884615384615384\n",
      "lev: 0.7903225806451613\n",
      "\n",
      "Quote: Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring. \n",
      "Completion: Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely b\n",
      "char: 0.9361702127659575\n",
      "lev: 0.9363636363636364\n",
      "\n",
      "Quote: Without music, life would be a mistake. \n",
      "Completion: Without music, life would be a mistake.\n",
      "—Friedrich\n",
      "char: 0.7674418604651163\n",
      "lev: 0.78\n",
      "\n",
      "Quote: The only true wisdom is in knowing you know nothing. \n",
      "Completion: The only true wisdom is in knowing you know nothing.\n",
      "I think we\n",
      "char: 0.8431372549019608\n",
      "lev: 0.8412698412698413\n",
      "\n",
      "Quote: The truth will set you free, but first it will piss you off. \n",
      "Completion: The truth will set you free, but first it will piss you off.\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9836065573770492\n",
      "\n",
      "Quote: There is no passion to be found playing small - in settling for a life that is less than the one you are capable of living. \n",
      "Completion: There is no passion to be found playing small - in settling for a life that is less than the one you are\n",
      "char: 0.8367346938775511\n",
      "lev: 0.8387096774193549\n",
      "\n",
      "Quote: If you want to go fast, go alone. If you want to go far, go together. \n",
      "Completion: If you want to go fast, go alone. If you want to go far, go together.\n",
      "char: 1.0\n",
      "lev: 0.9857142857142858\n",
      "\n",
      "Quote: You must be the change you wish to see in the world. \n",
      "Completion: You must be the change you wish to see in the world.\n",
      "- Mah\n",
      "char: 0.9111111111111111\n",
      "lev: 0.9137931034482759\n",
      "\n",
      "Quote: The greatest glory in living lies not in never falling, but in rising every time we fall. \n",
      "Completion: The greatest glory in living lies not in never falling, but in rising every time we fall\n",
      "char: 0.9863013698630136\n",
      "lev: 0.9777777777777777\n",
      "\n",
      "Quote: Life is either a daring adventure or nothing at all. \n",
      "Completion: Life is either a daring adventure or nothing at all.\n",
      "When you\n",
      "char: 0.86\n",
      "lev: 0.8688524590163934\n",
      "\n",
      "Quote: Success is not final, failure is not fatal: It is the courage to continue that counts. \n",
      "Completion: Success is not final, failure is not fatal: it is the courage to continue that counts.\n",
      "\n",
      "char: 1.0\n",
      "lev: 0.9770114942528736\n",
      "\n",
      "Quote: You have within you right now, everything you need to deal with whatever the world can throw at you. \n",
      "Completion: You have within you right now, everything you need to deal with whatever the world can throw at you\n",
      "char: 0.9878048780487805\n",
      "lev: 0.9801980198019802\n",
      "\n",
      "Quote: Life is 10% what happens to us and 90% how we react to it. \n",
      "Completion: Life is 10% what happens to us and 90% how we react to it\n",
      "char: 0.9777777777777777\n",
      "lev: 0.9661016949152542\n",
      "\n",
      "Quote: It is better to be hated for what you are than to be loved for what you are not. \n",
      "Completion: It is better to be hated for what you are than loved for what you are not.\n",
      "\n",
      "char: 0.6129032258064516\n",
      "lev: 0.9135802469135802\n",
      "\n",
      "Quote: In this world nothing can be said to be certain, except death and taxes. \n",
      "Completion: In this world nothing can be said to be certain, except death, taxes and\n",
      "char: 0.847457627118644\n",
      "lev: 0.8904109589041096\n",
      "\n",
      "Quote: The world breaks everyone, and afterward, some are strong at the broken places. \n",
      "Completion: The world breaks everyone, and afterward, many are strong in the broken places.\n",
      "The\n",
      "char: 0.8714285714285714\n",
      "lev: 0.8795180722891566\n",
      "\n",
      "Quote: Happiness is not something ready made. It comes from your own actions. \n",
      "Completion: Happiness is not something ready made. It comes from your own actions.\n",
      "The best\n",
      "char: 0.8939393939393939\n",
      "lev: 0.8987341772151899\n",
      "\n",
      "Quote: The roots of education are bitter, but the fruit is sweet. \n",
      "Completion: The roots of education are bitter, but the fruit is sweet.\n",
      "The\n",
      "char: 0.9411764705882353\n",
      "lev: 0.9354838709677419\n",
      "\n",
      "Quote: It's not what happens to you, but how you react to it that matters. \n",
      "Completion: It's not what happens to you, but how you react to it that matters.\n",
      "T\n",
      "char: 0.9818181818181818\n",
      "lev: 0.9710144927536232\n",
      "\n",
      "Quote: The only way to do great work is to love what you do. \n",
      "Completion: The only way to do great work is to love what you do. The only\n",
      "char: 0.8541666666666666\n",
      "lev: 0.8709677419354839\n",
      "\n",
      "Quote: Life isn't about finding yourself. Life is about creating yourself. \n",
      "Completion: Life isn't about finding yourself. Life is about creating yourself.\n",
      "I'm\n",
      "char: 0.9508196721311475\n",
      "lev: 0.9436619718309859\n",
      "\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Generate completions for each quote\n",
    "real_quotes = train_data[::2]\n",
    "\n",
    "quotes_first_half = []\n",
    "completions = []\n",
    "for quote in real_quotes:\n",
    "    quote_parts = quote.split()\n",
    "    first_half = \" \".join(quote_parts[:len(quote_parts)//2])\n",
    "    second_half = \" \".join(quote_parts[len(quote_parts)//2:])\n",
    "    quotes_first_half.append(first_half)\n",
    "    \n",
    "completions = mw.batch_generate_autoreg(quotes_first_half, max_new_tokens=10)\n",
    "\n",
    "# Evaluate completions\n",
    "evaluations = eval_completions(completions, real_quotes, return_mean = False)\n",
    "\n",
    "# Print the evaluations\n",
    "counter =0 \n",
    "memmed_quotes_idxs = []\n",
    "for i in range(len(real_quotes)):\n",
    "    if evaluations['lev_distance'][i] > 0.7:\n",
    "        print(f\"Quote: {real_quotes[i]}\")\n",
    "        print(f\"Completion: {completions[i]}\")\n",
    "        print(f\"char: {evaluations['char_by_char_similarity'][i]}\")\n",
    "        print(f\"lev: {evaluations['lev_distance'][i]}\")\n",
    "        print()\n",
    "        counter +=1\n",
    "        memmed_quotes_idxs.append(i)\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_train_data = []\n",
    "good_train_labels = []\n",
    "for idx in memmed_quotes_idxs:\n",
    "    good_train_data.extend(train_data[idx*2:idx*2+2])\n",
    "    good_train_labels.extend(train_labels[idx*2:idx*2+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quote_completion(s):\n",
    "    s = s.replace(\";\",\",\").split(\".\")[0].split(\"\\n\")[0]\n",
    "    return s.strip().lower()\n",
    "\n",
    "def quote_completion_test(data_dir):\n",
    "    with open(os.path.join(data_dir, \"quotes/quote_completions.json\")) as file:\n",
    "        test_data = json.load(file)\n",
    "    inputs = [i['input'] for i in test_data]\n",
    "    targets = [extract_quote_completion(i['target']) for i in test_data]\n",
    "    return inputs, targets\n",
    "\n",
    "### We do manually instead of rep_control_pipeline here as an example\n",
    "\n",
    "inputs, targets = quote_completion_test(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: the life in your years\n",
      "Completion: It's not the years in your life that count, it's the life in your years.\n",
      "-Abra\n",
      "\n",
      "Quote: waste it living someone else's life\n",
      "Completion: Your time is limited, don't waste it living someone else's life. Don\n",
      "\n",
      "Quote: no one ever come to you without leaving happier\n",
      "Completion: Spread love everywhere you go, let no one ever come to you without leaving happier\n",
      "\n",
      "Quote: we insist on making it complicated\n",
      "Completion: Life is really simple, but we insist on making it complicated. Life is\n",
      "\n",
      "Quote: how you make a positive difference to the world\n",
      "Completion: Success is not how high you have climbed, but how you make a difference to the world.\n",
      "\n",
      "\n",
      "Quote: will have to settle for the ordinary\n",
      "Completion: If you are not willing to risk the usual, you will have to settle for the ordinary.\n",
      "\n",
      "\n",
      "Quote: may only fail if you do not mind failing\n",
      "Completion: You may only succeed if you desire succeeding, you may only fail if you do not care about failing\n",
      "\n",
      "Quote: will be those who empower others\n",
      "Completion: As we look ahead into the next century, leaders will be those who empower others.\n",
      "B\n",
      "\n",
      "Quote: who are afraid to try and those who are afraid you will succeed\n",
      "Completion: There are two types of people who will tell you that you cannot make a difference in this world, those who are afraid to try and those who are afraid\n",
      "\n",
      "Quote: to love what you do\n",
      "Completion: The only way to do great work, is to love what you do.\n",
      "I'm\n",
      "\n",
      "Quote: you will be paid to do more than you do\n",
      "Completion: If you are willing to do more than you are paid to do, eventually you will be paid to do more than you do\n",
      "\n",
      "Quote: don't waste it living someone else's life\n",
      "Completion: Your time is limited, so don’t waste it living someone else’s\n",
      "\n",
      "Quote: we can build our youth for the future\n",
      "Completion: We cannot always build the future for our youth, but we can build our youth for the future.\n",
      "\n",
      "\n",
      "Quote: rather to be of value\n",
      "Completion: Strive not to be a success, but rather to be of value.\n",
      "It's\n",
      "\n",
      "Quote: waste it living someone else's life\n",
      "Completion: Your time is limited, don't waste it living someone else's life. Don\n",
      "\n",
      "Quote: if we chase perfection we can catch excellence\n",
      "Completion: Perfection is not attainable, but if we chase perfection we can catch excell\n",
      "\n",
      "Quote: 90% how we react to it\n",
      "Completion: Life is 10% what happens to us, and 90% how we react to it.\n",
      "\n",
      "Quote: tiny matters compared to what lies within us\n",
      "Completion: What lies behind us and what lies before us, are tiny matters compared to what lies within us.\n",
      "\n",
      "\n",
      "Quote: you from playing the game\n",
      "Completion: Never let the fear of striking out, keep you from playing the game.\n",
      "If you’\n",
      "\n",
      "Quote: to live the life of your dreams\n",
      "Completion: The biggest adventure you can take, is to live the life of your dreams.\n",
      "\n",
      "\n",
      "Quote: long as you do not stop\n",
      "Completion: It does not matter how slowly you go, as long as you do not stop.\n",
      "It is\n",
      "\n",
      "Quote: that the airplane takes off against the wind\n",
      "Completion: When everything seems to be going against you, remember that the airplane takes off against the wind,\n",
      "\n",
      "Quote: the life you've imagined\n",
      "Completion: Go confidently in the direction of your dreams, live the life you've imagined.\n",
      "I\n",
      "\n",
      "Quote: the bricks others have thrown at him\n",
      "Completion: A successful man is one who can lay a firm foundation, with the bricks others have thrown at him.\n",
      "\n",
      "\n",
      "Quote: led by the dreams in your heart\n",
      "Completion: Don't be pushed around by the fears in your mind, be led by the dreams in your heart.\n",
      "\n",
      "\n",
      "Quote: are you'll fall into someone else's plan\n",
      "Completion: If you don't design your own life plan, chances are you'll fall into someone else's\n",
      "\n",
      "Quote: more luck i seem to have\n",
      "Completion: I find that the harder I work, the more luck I seem to have.\n",
      "Luck\n",
      "\n",
      "Quote: will have to settle for the ordinary\n",
      "Completion: If you are not willing to risk the usual, you will have to settle for the ordinary.\n",
      "\n",
      "\n",
      "Quote: don't waste it living someone else's life\n",
      "Completion: Your time is limited, so don't waste it living someone else's\n",
      "\n",
      "Quote: believe in the beauty of their dreams\n",
      "Completion: The future belongs to those who believe in the beauty of their dreams.\n",
      "\n",
      "\n",
      "Quote: 10,000 ways that won't work\n",
      "Completion: I have not failed. I've just found 10,000 ways that won\n",
      "\n",
      "Quote: you can use to change the world\n",
      "Completion: Education is the most powerful weapon which you can use to change the world.\n",
      "It\n",
      "\n",
      "Quote: you something else is the greatest accomplishment\n",
      "Completion: To be yourself in a world that is constantly trying to make you something else is the greatest accomplishment.\n",
      "\n",
      "\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# Generate completions for each quote\n",
    "completions = mw.batch_generate_autoreg(inputs, max_new_tokens=10)\n",
    "\n",
    "decoded_outputs = [o.replace(i, \"\") for o,i in zip(completions, inputs)]\n",
    "\n",
    "# Evaluate completions\n",
    "evaluations = eval_completions(decoded_outputs, targets, return_mean = False)\n",
    "\n",
    "# Print the evaluations\n",
    "counter = 0 \n",
    "memmed_quotes_idxs = []\n",
    "for i in range(len(completions)):\n",
    "    if evaluations['lev_distance'][i] > 0.7:\n",
    "        print(f\"Quote: {targets[i]}\")\n",
    "        print(f\"Completion: {completions[i]}\")\n",
    "        # print(f\"char: {evaluations['char_by_char_similarity'][i]}\")\n",
    "        # print(f\"lev: {evaluations['lev_distance'][i]}\")\n",
    "        print()\n",
    "        counter +=1\n",
    "        memmed_quotes_idxs.append(i)\n",
    "print(counter)\n",
    "\n",
    "good_inputs, good_targets = np.array(inputs)[memmed_quotes_idxs].tolist(), np.array(targets)[memmed_quotes_idxs].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from act_add.rep_reader import PCARepReader\n",
    "quote_rep_reader = PCARepReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_steer_pipeline = SteeringPipeline(mw, quotes_dataset, quote_rep_reader)\n",
    "\n",
    "rep_token_idx = -1\n",
    "hidden_layers = list(range(model.config.num_hidden_layers))\n",
    "n_difference = 1\n",
    "\n",
    "# hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1)) #llama\n",
    "\n",
    "dirs = quote_steer_pipeline.gen_dir_from_strings(good_train_data, rep_token_idx, hidden_layers, n_difference, good_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepReader:\n",
      "No Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.7883911388044132, 'sem_similarity': 0.8854249589370958, 'lev_distance': 0.8152852183480366}\n",
      "+ Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.5128093342742073, 'sem_similarity': 0.6630788684794398, 'lev_distance': 0.6103939996859946}\n",
      "- Memorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_by_char_similarity': 0.37368384768071466, 'sem_similarity': 0.5502073281642162, 'lev_distance': 0.505909460666077}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layer_id = list(range(6, 15))\n",
    "# layer_id = list(range(-30,-38,-1)) #llama\n",
    "\n",
    "batch_size=64\n",
    "coeff=2.0 # tune this parameter\n",
    "max_new_tokens=10\n",
    "\n",
    "print(\"RepReader:\")\n",
    "print(\"No Control\")\n",
    "baseline_outputs = quote_steer_pipeline.batch_steering_generate(good_inputs, \n",
    "                                                                layer_id, \n",
    "                                                                coeff = 0 * coeff, \n",
    "                                                                batch_size = batch_size, \n",
    "                                                                use_tqdm=True, \n",
    "                                                                max_new_tokens=max_new_tokens)\n",
    "\n",
    "print(eval_completions(baseline_outputs, good_targets))\n",
    "\n",
    "print(\"+ Memorization\")\n",
    "pos_outputs = quote_steer_pipeline.batch_steering_generate(good_inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(pos_outputs, good_targets))\n",
    "\n",
    "print(\"- Memorization\")\n",
    "neg_outputs = quote_steer_pipeline.batch_steering_generate(good_inputs, \n",
    "                                                            layer_id, \n",
    "                                                            coeff = -coeff, \n",
    "                                                            batch_size = batch_size, \n",
    "                                                            use_tqdm=True, \n",
    "                                                            max_new_tokens=max_new_tokens)\n",
    "print(eval_completions(neg_outputs, good_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the life in your years',\n",
       " \"waste it living someone else's life\",\n",
       " 'no one ever come to you without leaving happier',\n",
       " 'we insist on making it complicated',\n",
       " 'how you make a positive difference to the world',\n",
       " 'will have to settle for the ordinary',\n",
       " 'may only fail if you do not mind failing',\n",
       " 'will be those who empower others',\n",
       " 'who are afraid to try and those who are afraid you will succeed',\n",
       " 'to love what you do']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" the life in your years.\\nIt's\",\n",
       " \" waste it living in the past.\\nDon'\",\n",
       " ' the world know that you care.\\n\"H',\n",
       " ' we insist on making it complicated.\\nLife',\n",
       " ' how you climb it.\\nIt is a',\n",
       " ' will have to settle for the usual.\\n',\n",
       " ' may only succeed if you desire succeeding, you',\n",
       " ' will be those who empower others.\\nThe',\n",
       " ' who are blind and those who are deaf.',\n",
       " ' to love what you do.\\nI love my']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' the moments.\\nA few weeks ago, I',\n",
       " \" waste it living someone else's life. Don\",\n",
       " ' it radiate from you like the sun.\\n',\n",
       " ' we insist on making it complicated.\\nWe',\n",
       " ' how many times you have lifted yourself up after falling',\n",
       " ' will most likely undergo the same.\\nIf',\n",
       " ' may only be successful if you want to be successful',\n",
       " ' in business, government, and nonprofit organizations',\n",
       " ' who are cynical and those who are afraid',\n",
       " ' to be great at what you do. The only']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_outputs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
