{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from utils import untuple\n",
    "from model_utils import ModelWrapper\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# test that hooks work\n",
    "device = \"cuda\"\n",
    "prompt = \"Testing that hooks work\"\n",
    "\n",
    "mt = ModelWrapper(\"EleutherAI/pythia-160m\", device = \"cuda\")\n",
    "mt.register_layer_hooks()\n",
    "\n",
    "toks = mt.tokenizer.encode(prompt, return_tensors = 'pt').to(device)\n",
    "\n",
    "out= mt.model.generate(\n",
    "    input_ids=toks,\n",
    "    attention_mask = torch.ones_like(toks),\n",
    "    max_new_tokens=10,\n",
    "    top_p=1.0,\n",
    "    output_hidden_states=True,\n",
    "    return_dict_in_generate = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(out['hidden_states'][-1][11], mt.save_ctx['gpt_neox.layers.10'].activations)\n",
    "assert torch.equal(out['hidden_states'][-1][12], mt.model.gpt_neox.final_layer_norm(mt.save_ctx['gpt_neox.layers.11'].activations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
